{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/ngzhiwei517/Water-Volume-Prediction-for-Lakes-and-Reservoirs/blob/main/water_volume_prediction_.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Prediciton of Lake Water Volume Changes"
      ],
      "metadata": {
        "id": "cBMP4ZN7i8VK"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 1.0 Introduction"
      ],
      "metadata": {
        "id": "j2QJOFrTioNF"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 1.1 Group information"
      ],
      "metadata": {
        "id": "lVXjPvcceTHw"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Group Name: HydroDS (Group 15)\n",
        "\n",
        "Group Member:\n",
        "- 23054206 NG YU HENG\n",
        "- 23005031 CHANG CAI TING\n",
        "- 23005000 CHUA HUI MIN\n",
        "- 23005227 KUEH PANG LANG\n",
        "- 23051966 NG ZHI WEI\n",
        "- 23004979 POH JING MIN"
      ],
      "metadata": {
        "id": "3a6aiKHDecRC"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 1.2 Problems and Solutions"
      ],
      "metadata": {
        "id": "EMmvBzUIeYWW"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Our project is about predicting the changes of water volume in 24 hours of a lake or a resevoir by the conditions of the weather."
      ],
      "metadata": {
        "id": "yWa13Q93irfY"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Recently, Penang has been facing a critical issue where their water resevoirs are low on water. The water supply is only enough to last for another 30 days. These show that the people working at the water resevoirs fail to have an effective long term plan when dealing with climate changes to make sure that the water level in the dam is sufficient for supplying to the people. 10 years ago, Cameron Highlands experienced a tragedy where the water of the dam was released only when the water exceed its safety level due to heavy rain falls and caused a lighting flood. This show that the people working at the dam fail to take effective action when dealing with sudden changes of weather conditions.\n",
        "\n"
      ],
      "metadata": {
        "id": "dGbKvvpajZKA"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "From the situations above, we can see that weather is the major factor affecting the water volume in the water resevoirs or dam."
      ],
      "metadata": {
        "id": "nqaIWZtdUhPX"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "To solve the problems, we come up with two solutions:\n",
        "- **Water volume changes prediction for unusual weather conditions**\n",
        "- Water volume changes forecasting for climate changes\n",
        "\n",
        "With the help of prediction and forecasting, it allow the responsible party to take early action to prevent the above issues to happen."
      ],
      "metadata": {
        "id": "uSWcxOcIfKSX"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "For this project, we will be focusing on **prediction for water volume changes in 24 hours**."
      ],
      "metadata": {
        "id": "15CqM-N9fern"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 2.0 Data Mining"
      ],
      "metadata": {
        "id": "dn6AaSxBa0P-"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 2.1 Lake dataset"
      ],
      "metadata": {
        "id": "p6D-RHgPmu-l"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "After surfing through the Internet, we found that we were unable to find any historical data about the water level of the dam in Malaysia. The most we can get is the current data which is too little to train our model even if we start collecting it by April 2024. Hence, we decided to look for data out of Malaysia."
      ],
      "metadata": {
        "id": "TztG9_EYJ45l"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Luckily for us, we were able to find a website which contain the historical data regarding a few lakes located in Phoenix, AZ, USA. In order to extract those data out and store it in a .csv file, we have to perform Web Scrapping."
      ],
      "metadata": {
        "id": "b8HORV3wJ7jC"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 2.1.1 Inspecting the website (Lake dataset)"
      ],
      "metadata": {
        "id": "7YHAKVQRwPyS"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Before scrapping the data out from the website, we make some discovering about the website first and understand where the data is stored and how to extract the data for a period of time by performing the following code."
      ],
      "metadata": {
        "id": "HDDMEBpvm2IM"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "We need the help of some packages in order to perform web scrapping.\n",
        "- BeautifulSoup\n",
        "- requests"
      ],
      "metadata": {
        "id": "gCMLI8bgnkzu"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Import required packages\n",
        "from bs4 import BeautifulSoup\n",
        "import requests"
      ],
      "metadata": {
        "id": "84peflWTaz8l"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "First, we try to get request from the website.\n",
        "\n",
        "\n",
        "---\n",
        "\n",
        "Source: https://www.watershedconnection.com/"
      ],
      "metadata": {
        "id": "h2qjeSfSn1pD"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Website for data mining\n",
        "url = \"https://streamflow.watershedconnection.com/DWR?reportDate=2017-1-1\""
      ],
      "metadata": {
        "id": "tBp_nCDcbJPc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Get requests from website\n",
        "requests.get(url)"
      ],
      "metadata": {
        "id": "3LeR8IbEoHeX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "It returns us a response 200. Response 200 indicates that our request to the website has succeeded."
      ],
      "metadata": {
        "id": "twGWaAahoMdl"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Now, we try to get the HTML of the website."
      ],
      "metadata": {
        "id": "Jkz-fHgcoke7"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Get requests from website\n",
        "page_lake_test = requests.get(url)"
      ],
      "metadata": {
        "id": "A2A5y8MkbVSA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Get the html of the website\n",
        "soup_lake_test = BeautifulSoup(page_lake_test.text, 'html')"
      ],
      "metadata": {
        "id": "-plU_ZyNblrG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Print the html of the website\n",
        "print(soup_lake_test.prettify())"
      ],
      "metadata": {
        "id": "wPrXcfYzcKfQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Well, there is quite a lot of code in the HTML. By inspecting the website, we know that the table containing the data is code under the tags 'table'. Let's have a search for the tags 'table'."
      ],
      "metadata": {
        "id": "PALPCtQHo93r"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Find all 'table' in the html (Searching for the tags containing the table of the data)\n",
        "soup_lake_test.find_all('td')"
      ],
      "metadata": {
        "id": "iQyGopyvcenf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "There is the tags 'table' containing the data we want. However, there are also other tables in that website too. We select the table we want by adding a '[0]' at the end of the previous code."
      ],
      "metadata": {
        "id": "awD7fjz4pnNf"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Find all 'table' in the html (Searching for the tags containing the table of the data)\n",
        "soup_lake_test.find_all('table')[0]"
      ],
      "metadata": {
        "id": "W90pGInqpoNO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "The table we wanted has been selected. From the code, we able to see that the data we wanted is under the tags 'td'. Let's try to get the data out."
      ],
      "metadata": {
        "id": "zrnWYHg8qVq6"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Find all 'td' in the html (Searching for the data we wanted)\n",
        "soup_lake_test.find_all('td')"
      ],
      "metadata": {
        "id": "W2wqs71jqr4m"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Let's pull the first data out from the tags to see whether the data is in the format that we wanted."
      ],
      "metadata": {
        "id": "CjYbgSDYrJJH"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Pulling text information from the website\n",
        "soup_lake_test.find('td').text"
      ],
      "metadata": {
        "id": "izo08Gy1rbXh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Well, almost there but it containing something that we don't want. Let's trim it off."
      ],
      "metadata": {
        "id": "CFBR9EgGraCl"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Pulling text information from the website\n",
        "soup_lake_test.find('td').text.strip()"
      ],
      "metadata": {
        "id": "3i7V0K7je0on"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Nice, this is what we wanted."
      ],
      "metadata": {
        "id": "fxAFKzNBr9AX"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "The websites also containing some information of the weather for that respective day. From the inspection of the websites, the weather data is code under the 'b' tags."
      ],
      "metadata": {
        "id": "BkXUsmy0sCRj"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Find all 'b' in the html (Searching for the weather data)\n",
        "soup_lake_test.find_all('b')"
      ],
      "metadata": {
        "id": "KkHic5bnsgto"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Each data is in the format highest/lowest. So, let us try to separate the first data."
      ],
      "metadata": {
        "id": "GAAl4F0lslzf"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Separating the data and removing unwanted value from the data\n",
        "temperature_test = soup_lake_test.find_all('b')[0]\n",
        "temperature_list_test = temperature_test.text.strip().split(\"°\")\n",
        "temperature_list_test[1] = temperature_list_test[1].replace(\"/\", \"\")\n",
        "temperature_list_test"
      ],
      "metadata": {
        "id": "NYgVNaLBhPVG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "From the above list, we know that the data one is the first and the second items in the list."
      ],
      "metadata": {
        "id": "wOJdJLLYtkJb"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Since we know where our data is located in the website, it's time to extract those data and store it in a dataframe."
      ],
      "metadata": {
        "id": "RoESU_qPtvmu"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Selecting the table needed\n",
        "table_lake_test = soup_lake_test.find_all('table')[0]"
      ],
      "metadata": {
        "id": "kBhoOwnxgfx5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Before creating the dataframe, we need to set the feature names first. The feature names are under the tags 'th'. Let's have a look of it."
      ],
      "metadata": {
        "id": "6qFPJe1IuNkX"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Find all 'th' in the html (Searching for the feature names)\n",
        "soup_lake_test.find_all('th')"
      ],
      "metadata": {
        "id": "MsuXDQ0jitdd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "That was an unexpected coding. We have no choice to set the feature names ourself."
      ],
      "metadata": {
        "id": "-yiHpgSCuy5h"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Setting the feature names manually into a list\n",
        "feature_names_lake_test = ['Location', 'Full (%)', 'Current Elevation(ft)',\n",
        "                      'Current Storage (af)', 'Remaining Elevation (ft)',\n",
        "                      'Available Storage (af)', '24 hr. Change',\n",
        "                      'Rain (inches)']\n",
        "feature_names_lake_test"
      ],
      "metadata": {
        "id": "gNHkmxLsjUuc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "This is better. Now we will create a dataframe and set the feature names into it."
      ],
      "metadata": {
        "id": "cPGWE5RpvEc4"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd"
      ],
      "metadata": {
        "id": "wYiNb_Qmkh5b"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "lake_test_df = pd.DataFrame(columns = feature_names_lake_test)\n",
        "lake_test_df"
      ],
      "metadata": {
        "id": "rsdOwepmkqZU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Looks good up until here."
      ],
      "metadata": {
        "id": "VExqFD9GvjRj"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Now it is time to abtract the data we wanted and storing it into the dataframe."
      ],
      "metadata": {
        "id": "r3MORhWpvwpe"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "column_data_lake_test = table_lake_test.find_all('tr')"
      ],
      "metadata": {
        "id": "bGx4FaWVluZz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for row in column_data_lake_test[2:]:\n",
        "  row_data = row.find_all('td')\n",
        "  individual_row_data = [data.text.strip() for data in row_data]\n",
        "\n",
        "  length = len(lake_test_df)\n",
        "  lake_test_df.loc[length] = individual_row_data\n",
        "\n",
        "lake_test_df"
      ],
      "metadata": {
        "id": "cNT06laGlKYh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Seems like the web scrapping works for this website as the data we wanted is successfully extract from the website into the dataframe. Now, we will be moving to the next step which is extracting data for a range of time."
      ],
      "metadata": {
        "id": "zFkcu6RRFGVV"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 2.1.2 Extracting data for a range of time (Lake dataset)"
      ],
      "metadata": {
        "id": "iK9upeCeFCAb"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Setting up the date range for the data we wanted to extract."
      ],
      "metadata": {
        "id": "WcysoNYSwxoV"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Import package needed for convertion between text and date\n",
        "from datetime import datetime, timedelta"
      ],
      "metadata": {
        "id": "2PizMmYHxjUH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Set Date range\n",
        "date_start_text = \"2013-1-1\"\n",
        "date_end_text = \"2023-1-1\"\n",
        "freq_text = \"1\""
      ],
      "metadata": {
        "id": "3K-Lid86FhGs"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "The range of our data gathering will be daily for a period of 10 years."
      ],
      "metadata": {
        "id": "umhfEJWgqS9s"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "The convertion from text to date is necessary to be put as the range of the while loop."
      ],
      "metadata": {
        "id": "tiiT5UH9q7ym"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Convert text to date\n",
        "date_start_inc = date_start_text\n",
        "date_start_inc_date = datetime.strptime(date_start_inc, \"%Y-%m-%d\")\n",
        "date_end_date = datetime.strptime(date_end_text, \"%Y-%m-%d\")\n",
        "freq_obj = int(freq_text)\n",
        "\n",
        "date_start_inc_date = date_start_inc_date.date()\n",
        "date_end_date = date_end_date.date()"
      ],
      "metadata": {
        "id": "ZZqTZ9EFF1vV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Setting up the feature names needed for the dataframe."
      ],
      "metadata": {
        "id": "vsskNrvlx-hZ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Setting up features name\n",
        "feature_names_lake = [ 'Location', 'Full_%', 'Current_Elevation_ft',\n",
        "                      'Current_Storage_af', 'Remaining_Elevation_ft',\n",
        "                      'Available_Storage_af', '24hr.Change',\n",
        "                      'Rain_inches', 'Date', 'Highest_temperature',\n",
        "                       'Lowest_temperature','Highest_humidity',\n",
        "                       'Lowest_humidity']\n",
        "feature_names_lake"
      ],
      "metadata": {
        "id": "0qu526tpGNDH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "There will be a total of 13 features for this dataset"
      ],
      "metadata": {
        "id": "fYGrGhkerSbg"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Setting up the dataframe to store data later with the feature names we set previously\n",
        "lake_df = pd.DataFrame(columns = feature_names_lake)"
      ],
      "metadata": {
        "id": "yxNJ75PbGr40"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Our dataframe is ready to store data gather from the website"
      ],
      "metadata": {
        "id": "sEdhFKqEsfiJ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Using the while loop to gather data for a period of time\n",
        "while date_start_inc_date <= date_end_date:\n",
        "  # Date will be automatically insert to the back of the url to access data for that particular day\n",
        "  url = 'https://streamflow.watershedconnection.com/DWR?reportDate='+ date_start_inc_date.strftime(\"%Y-%m-%d\")\n",
        "  page_lake = requests.get(url)\n",
        "  soup_lake = BeautifulSoup(page_lake.text, 'html')\n",
        "  table_lake = soup_lake.find_all('table')[0]\n",
        "  column_data_lake = table_lake.find_all('tr')\n",
        "  for row_lake in column_data_lake[2:]:\n",
        "    row_data_lake = row_lake.find_all('td')\n",
        "    individual_row_data_lake = [data.text.strip() for data in row_data_lake]\n",
        "    individual_row_data_lake.append(date_start_inc_date.strftime(\"%Y-%m-%d\"))\n",
        "    # Triming the temperature value and adding it into the list\n",
        "    temperature = soup_lake.find_all('b')[0]\n",
        "    temperature_list = temperature.text.strip().split(\"°\")\n",
        "    temperature_list[1] = temperature_list[1].replace(\"/\", \"\")\n",
        "    individual_row_data_lake.append(temperature_list[0])\n",
        "    individual_row_data_lake.append(temperature_list[1])\n",
        "    # Triming the humidity value and adding it into the list\n",
        "    humidity = soup_lake.find_all('b')[2]\n",
        "    humidity_list = humidity.text.strip().split()\n",
        "    individual_row_data_lake.append(humidity_list[0])\n",
        "    individual_row_data_lake.append(humidity_list[2])\n",
        "    # Storing the list of data into the dataframe\n",
        "    length = len(lake_df)\n",
        "    lake_df.loc[length] = individual_row_data_lake\n",
        "\n",
        "  date_start_inc_date = date_start_inc_date + timedelta(days = freq_obj)"
      ],
      "metadata": {
        "id": "gjOv2Q9yLSRL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Having a look at the dataframe."
      ],
      "metadata": {
        "id": "66O6XwvFVbny"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Print out a dataframe\n",
        "lake_df"
      ],
      "metadata": {
        "id": "uPGsyZkSBMx9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "From the table above, the data we gather has correctly store in their respective column. A total of 36530 rows of data gather for 10 years period"
      ],
      "metadata": {
        "id": "KCnOEYNhuaqy"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "lake_df.to_csv(r'/content/sample_data/lake_dataset_10years.csv', index = False)"
      ],
      "metadata": {
        "id": "W9aAxm-OudnF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "We save the data gather into a csv file."
      ],
      "metadata": {
        "id": "fKWDWkrvufkL"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "After inspecting the dataset, we found out the weather information gather from that website is not precise enough. Hence, we decided to gather the information of the weather from the nearest weather station to the area where the lakes are located from other website."
      ],
      "metadata": {
        "id": "MpE1MNG9uhin"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 2.2 Weather dataset"
      ],
      "metadata": {
        "id": "eAMVd5BJVlte"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "First we need to see which weather station is the nearest to that area. Only the weather station at the airport in that area is storing the historical weather data."
      ],
      "metadata": {
        "id": "EwdBjoZou0rv"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "The airport available there is as follow:\n",
        "- Phoenix Sky Harbor International Airport\n",
        "- Phoenix-Mesa Gateway Airport\n",
        "- Falcon Field Airport\n",
        "- Scottsdale Airport\n",
        "- Phoenix Deer Valley Airport\n",
        "- Glendale Municipal Airport\n",
        "- Phoenix-Goodyear Airport\n"
      ],
      "metadata": {
        "id": "jsiL3KqTu7uf"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "We have chosen Falcon Field Airport since it is nearest to that area."
      ],
      "metadata": {
        "id": "b664BN9ZwOVi"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "We now gather the data about the weather information of that area from this website.\n",
        "\n",
        "---\n",
        "\n",
        "\n",
        "Source: https://www.visualcrossing.com/"
      ],
      "metadata": {
        "id": "p9EM_lmuumgW"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 2.2.1 Inspecting the website (Weather dataset)"
      ],
      "metadata": {
        "id": "dhiwtlPm_pmU"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "After taking a tour through this website, it's provide API that allow user to get the data from their website easily. However, for free user, a total of 1000 records are allowed for a day. This mean that we need a few day to gather all the data we wanted."
      ],
      "metadata": {
        "id": "IpyArNIg_wb5"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Since API service is provided, it save up a lot of our works to inspect the website."
      ],
      "metadata": {
        "id": "Ib4EJtzMB_6R"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 2.2.2 Extracting data for a range of time (Weather dataset)"
      ],
      "metadata": {
        "id": "9bNAQKvA9ynw"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "As same as previous, we first need to indicate the range of date of the data we wanted to extract. Since we are only able to extract limited data per day, in this notebook, we will only be extracting data for a period of one year."
      ],
      "metadata": {
        "id": "VqQdO5Tr902U"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Set Date range\n",
        "date_start_text = \"2013-1-1\"\n",
        "date_end_text = \"2014-1-1\"\n",
        "freq_text = \"1\""
      ],
      "metadata": {
        "id": "BGQx-RXY_BQ6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Converting the date from string into date"
      ],
      "metadata": {
        "id": "PI_qpqsL_b78"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Convert text to date\n",
        "date_start_inc = date_start_text\n",
        "date_start_inc_date = datetime.strptime(date_start_inc, \"%Y-%m-%d\")\n",
        "date_end_date = datetime.strptime(date_end_text, \"%Y-%m-%d\")\n",
        "freq_obj = int(freq_text)\n",
        "\n",
        "date_start_inc_date = date_start_inc_date.date()\n",
        "date_end_date = date_end_date.date()"
      ],
      "metadata": {
        "id": "87oKpNMp_jOY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "We now start to extract the data we wanted using the API. We will be getting weather information for a day for each query we make. Hence, we need to create a list to store all the dataframe we get so that we can combine it into one later."
      ],
      "metadata": {
        "id": "POye9g7ICVaz"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Creating the list to store the .csv file\n",
        "list_of_csv = []\n",
        "# Creating the while loop\n",
        "while date_start_inc_date <= date_end_date:\n",
        "  url = 'https://weather.visualcrossing.com/VisualCrossingWebServices/rest/services/timeline/%20Falcon%20Field%20Airport%2C%204800%20E%20Falcon%20Dr%2C%20Mesa/'+date_start_inc_date.strftime(\"%Y-%m-%d\")+'/' +date_start_inc_date.strftime(\"%Y-%m-%d\")+'?unitGroup=metric&include=days&key={API KEY}&contentType=csv'\n",
        "  df = pd.read_csv(url, index_col=None, header = 0)\n",
        "  date_start_inc_date = date_start_inc_date + timedelta(days = freq_obj)\n",
        "  # Adding the dataframe into the list\n",
        "  list_of_csv.append(df)"
      ],
      "metadata": {
        "id": "LB41nn3O_5G8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "We proceed with the combination of the dataframe"
      ],
      "metadata": {
        "id": "2R_3XmSuCtTS"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Combining all the dataframe in the list into one\n",
        "weather_2013_df = pd.concat(list_of_csv, axis= 0,ignore_index=True)"
      ],
      "metadata": {
        "id": "JgG8-iTfxDUL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Let's have a glance through the dataframe we combined"
      ],
      "metadata": {
        "id": "QxTj3YpYC0VL"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Print the dataset\n",
        "weather_2013_df"
      ],
      "metadata": {
        "id": "jsddmITcxa-U"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Everything looks good. Time to save it into a .csv file for later use."
      ],
      "metadata": {
        "id": "o8X3sOAwC7bM"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Saving the dataframe into a .csv file\n",
        "weather_2013_df.to_csv(r'/content/sample_data/weather_dataset_2013.csv', index = False)"
      ],
      "metadata": {
        "id": "a13ySKp4AgDE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Now, we have the weather dataset for the year 2013. The dataset for the remaining years will be done using another notebook by using the same code as above."
      ],
      "metadata": {
        "id": "1BpNKmhYAsO1"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Since all of the dataset we wanted are ready, it's time to proceed to the next section,which is Data Preprocessing."
      ],
      "metadata": {
        "id": "r2w7h0SXA7rz"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kLajhCs69Y4Z"
      },
      "source": [
        "# 3.0 Data cleaning and preprocessing"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sHNuewVOUXCP"
      },
      "source": [
        "Data cleaning is the initial phase of refining dataset, making it readable and usable with techniques like removing and usable with techniques such as handling missing values, changing data types, removing duplicates etc."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "t12jCqZ5UpPm"
      },
      "source": [
        "Data preprocessing take place to refine data and scaling with more advanced techniques such as encoding categorical variables. handling outliers in order to achieve a better results."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_uBykTgzqbSR"
      },
      "source": [
        "# 3.1 Data loading"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "okRo2I4Iq7hj"
      },
      "source": [
        " Import lake dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2SKllYRrbrV3"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "\n",
        "# Importing lake dataset\n",
        "lake_10years_df=pd.read_csv(\"/content/lake_dataset_10years.csv\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZT30lhurrByK"
      },
      "source": [
        "Import weather dataset from year 2013 to 2022"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "u-Uldv9y6ubn"
      },
      "outputs": [],
      "source": [
        "# Importing dataset\n",
        "\n",
        "# Each dataframe have been predefined to prevent conflict between the datafrane variable name of two different notebooks\n",
        "\n",
        "# Importing weather dataset\n",
        "\n",
        "weather_2013_df = pd.read_csv(\"/content/weather_dataset_cv_2013.csv\")\n",
        "weather_2014_df = pd.read_csv(\"/content/weather_dataset_cv_2014.csv\")\n",
        "weather_2015_df = pd.read_csv(\"/content/weather_dataset_cv_2015.csv\")\n",
        "weather_2016_df = pd.read_csv(\"/content/weather_dataset_cv_2016.csv\")\n",
        "weather_2017_df = pd.read_csv(\"/content/weather_dataset_cv_2017.csv\")\n",
        "weather_2018_df = pd.read_csv(\"/content/weather_dataset_cv_2018.csv\")\n",
        "weather_2019_df = pd.read_csv(\"/content/weather_dataset_cv_2019.csv\")\n",
        "weather_2020_df = pd.read_csv(\"/content/weather_dataset_cv_2020.csv\")\n",
        "weather_2021_df = pd.read_csv(\"/content/weather_dataset_cv_2021.csv\")\n",
        "weather_2022_df = pd.read_csv(\"/content/weather_dataset_cv_2022.csv\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Y4iwlRXRr1wj"
      },
      "source": [
        "To merge all the weather datasets into one dataframe, we created a list called list_of_csv to store DataFrame objects. The list contains DataFrame variables named weather_2013_df, weather_2014_df, and so on up to weather_2022_df, each presumably holding weather data for a specific year."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "uy9QX54gpCjl"
      },
      "outputs": [],
      "source": [
        "# Creating the list to store the .csv file\n",
        "list_of_csv = [weather_2013_df,weather_2014_df,weather_2015_df,weather_2016_df,\n",
        "               weather_2017_df,weather_2018_df,weather_2019_df,weather_2020_df,\n",
        "               weather_2021_df,weather_2022_df]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pXChFr5Yrz91"
      },
      "source": [
        "We combines all the DataFrames stored in the list_of_csv into a single DataFrame named weather_10years_df."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "N9fJp4Y1pCgX"
      },
      "outputs": [],
      "source": [
        "# Combining all the dataframe in the list into one\n",
        "weather_10years_df = pd.concat(list_of_csv, axis= 0,ignore_index=True)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yCnK2okHseSV"
      },
      "source": [
        "Let have a look for our merged dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Uyd89uhFpCdk"
      },
      "outputs": [],
      "source": [
        "# Print the dataset\n",
        "weather_10years_df\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-nun7fs517Zm"
      },
      "source": [
        "#Optional\n",
        "Dowload the combine csv file to your local repository"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "E3lMG7nypCWM"
      },
      "outputs": [],
      "source": [
        "# Save the combined DataFrame as a CSV file\n",
        "weather_10years_df.to_csv('Weather_10years.csv', index=False)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "V6bZoQP31zf3"
      },
      "outputs": [],
      "source": [
        "from google.colab import files\n",
        "\n",
        "files.download('Weather_10years.csv')\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hnfnCHbbEVNA"
      },
      "source": [
        "# 3.2 Data cleaning"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WnGjaqY0-Cu1"
      },
      "source": [
        "# 3.2.1 Overview the dataset"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GE0LulxAGRiu"
      },
      "source": [
        "**Lake dataset**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "q7AcPEeV-xRr"
      },
      "outputs": [],
      "source": [
        "# Checking data\n",
        "print(\"\\nInformation of the dataset\")\n",
        "print(lake_10years_df.info())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "F2D4JvAbKmY3"
      },
      "outputs": [],
      "source": [
        "print(\"\\nNumber of unique value for each column\")\n",
        "print(lake_10years_df.nunique())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "sHnxtreVKopr"
      },
      "outputs": [],
      "source": [
        "print(\"\\nDetermining the data types\")\n",
        "print(lake_10years_df.dtypes)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8OOAWrusK1Ae"
      },
      "source": [
        "All of the data extracted from the website are stored as String rather then integer. Convertion should be made as most of the data such as current elevation, current storage etc. should be integer."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1njLjxlvE-XY"
      },
      "outputs": [],
      "source": [
        "print(f'The dateset has {lake_10years_df.shape[0]} rows and {lake_10years_df.shape[1]} columns.')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "c-MtjXNORGxG"
      },
      "source": [
        "From the information above, we know that the dataset contains 36530 rows of data and 13 features."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Yuarrvu9IeK_"
      },
      "source": [
        "Identify the column"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "oMb1glHUILxH"
      },
      "outputs": [],
      "source": [
        "print('Columns of dataset\\n__________________________________________________________________________________________________')\n",
        "# Print the columns of the dataset\n",
        "print('Lake Dataset:', lake_10years_df.columns)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "y61WRuD0LX3A"
      },
      "source": [
        "The above are the list of features name for the lake dataset."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fj9AyXttf1lM"
      },
      "source": [
        "**Weather dataset**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "lCKQ0KhRf9TM"
      },
      "outputs": [],
      "source": [
        "#Checking data\n",
        "print(\"\\nPrint information of the dataset: \")\n",
        "print(weather_10years_df.info())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-X066nLuPpZL"
      },
      "outputs": [],
      "source": [
        "print(\"\\nNumber of unique value for each column\")\n",
        "print(weather_10years_df.nunique())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jMk3y16CPrlg"
      },
      "outputs": [],
      "source": [
        "print(\"\\nDetermining the data types\")\n",
        "print(weather_10years_df.dtypes)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Dut4fKrPQ4uM"
      },
      "source": [
        "There are some categorical data in the dataset that need to be encode later in the data preprocessing process."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vfQ_y8MgjeBu"
      },
      "outputs": [],
      "source": [
        "print(f'The dateset has {weather_10years_df.shape[0]} rows and {weather_10years_df.shape[1]} columns.')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dcwflUDzP0kY"
      },
      "source": [
        "From the information above, we know that the dataset contains 3662 rows of data and 33 features."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5gyIfMocpIS_"
      },
      "source": [
        "Identify the column"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "f330sz25pHEH"
      },
      "outputs": [],
      "source": [
        "print('Columns of dataset\\n__________________________________________________________________________________________________')\n",
        "# Print the columns of the dataset\n",
        "print('Weather Dataset: ', weather_10years_df.columns)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NoU3jwp2P8Yt"
      },
      "source": [
        "The above are the list of features name of the weather dataset."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uxGJZvcsBb53"
      },
      "source": [
        "# 3.2.2 Lake data modifiying"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pMCbWx1QHZ-r"
      },
      "source": [
        "We wanted to use the the previous day storage capacity as a feature to predict the change of volume of the lake in 24 hours. A small modifying to the dataset is needed. We will be creating a new column with the title 'Previous_Storage_af'."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "n4MwPiYsI1bS"
      },
      "source": [
        "We will use the data from the features, 'Current_Storage_af' and shift the data 10 rows downward. Now we will have a feature which contains the volume of the storage of the previous day."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ntRmbSzBvuhA"
      },
      "outputs": [],
      "source": [
        "# Having a look at the lake dataset\n",
        "lake_10years_df"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "nSINGx2jHH5M"
      },
      "outputs": [],
      "source": [
        "# Creating a new column named 'Previous_Storage_af'\n",
        "# Using the data from column named 'Current_Storage_af', shifting it 10 rows downward, and store in that column\n",
        "lake_10years_df.insert(3, \"Previous_Storage_af\", lake_10years_df[\"Current_Storage_af\"].shift(10))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zTdiMdz_ILfu"
      },
      "outputs": [],
      "source": [
        "# Printing the lake dataset again to see the added column\n",
        "lake_10years_df.head(20)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Az12BwbUSFeU"
      },
      "source": [
        "A new feature is created by modifying one of the existing features. However, null values existed in this new features because of the shifting of data. It will be remove later in the data preprocessing process."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1aybcpGGGuJV"
      },
      "source": [
        "# 3.2.3 Rename the date column"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9xQTW9G2GzP5"
      },
      "source": [
        "We choose to rename the 'Date' column to 'datetime' in the lake DataFrame since we noticed that the weather dataset uses 'datetime' as the column name for the corresponding information. This adjustment ensures consistency across datasets and facilitates seamless data integration."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ZPxQXgZ-G1Yh"
      },
      "outputs": [],
      "source": [
        "# Renaming the 'Date' column to 'datetime'\n",
        "lake_10years_df.rename(columns={'Date': 'datetime'}, inplace=True)\n",
        "\n",
        "# Check the updated column names\n",
        "print(\"\\nFeatures of the dataset \")\n",
        "print(lake_10years_df.columns)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wv19jLdcV0Op"
      },
      "source": [
        "# 3.2.4 Choosing a lake location and removing the others"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8ELYZlkLWKpA"
      },
      "source": [
        "From the lake datasets, it contains a few lake locations that can be selected for prediction. However, including all the locations will affect the accuracy of the prediction."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2xzfmCPLXpLU"
      },
      "source": [
        "Hence, a discussion has been made and we decided to select one location only which is Roosevelt Lake (Roosevelt Dam) for our prediction."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "u44fCkX7Vyum"
      },
      "outputs": [],
      "source": [
        "# Removing unwanted locations\n",
        "lake_10years_df = lake_10years_df.drop(lake_10years_df[lake_10years_df['Location'] == 'Apache Lake (Horse Mesa Dam)'].index)\n",
        "lake_10years_df = lake_10years_df.drop(lake_10years_df[lake_10years_df['Location'] == 'Canyon Lake (Mormon Flat Dam)'].index)\n",
        "lake_10years_df = lake_10years_df.drop(lake_10years_df[lake_10years_df['Location'] == 'Saguaro Lake (Stewart Mountain Dam)'].index)\n",
        "lake_10years_df = lake_10years_df.drop(lake_10years_df[lake_10years_df['Location'] == 'Horseshoe Lake (Horseshoe Dam)'].index)\n",
        "lake_10years_df = lake_10years_df.drop(lake_10years_df[lake_10years_df['Location'] == 'Bartlett Lake (Bartlett Dam)'].index)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "pUEeb4aeYAjF"
      },
      "outputs": [],
      "source": [
        "# Having a look at the lake dataset\n",
        "lake_10years_df"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "N_xyBG5GzvE2"
      },
      "source": [
        "# 3.2.5 Replace Missing Values for selected features"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "E-0fGyXddDoI"
      },
      "source": [
        "To avoid losing too much potential data when removing null value by using the command dropna(), we decided to replace the null value with suitable value for some features."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6gx34vvaZOVY"
      },
      "outputs": [],
      "source": [
        "print(\"\\nFind missing value of each column\")\n",
        "print(lake_10years_df.isna().sum())\n",
        "\n",
        "print(\"\\nFind missing value of each column\")\n",
        "print(weather_10years_df.isna().sum())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "JICPfjaLz8_M"
      },
      "outputs": [],
      "source": [
        "# Replace missing values in the 'precitype' column with 'none'\n",
        "weather_10years_df['preciptype'].fillna('none', inplace=True)\n",
        "\n",
        "# Replace missing values in the 'snow' column with mean\n",
        "weather_10years_df['snow'].fillna(weather_10years_df['snow'].mean(), inplace=True)\n",
        "\n",
        "# Replace missing values in the 'snowdepth' column with mean\n",
        "weather_10years_df['snowdepth'].fillna(weather_10years_df['snowdepth'].mean(), inplace=True)\n",
        "\n",
        "# Replace missing values in the 'windgust' column with 0\n",
        "weather_10years_df['windgust'].fillna(0, inplace=True)\n",
        "\n",
        "# Replace missing values in the 'solarradiation' column with mean\n",
        "weather_10years_df['solarradiation'].fillna(weather_10years_df['solarradiation'].mean(), inplace=True)\n",
        "\n",
        "# Replace missing values in the 'solarenergy' column with mean\n",
        "weather_10years_df['solarenergy'].fillna(weather_10years_df['solarenergy'].mean(), inplace=True)\n",
        "\n",
        "# Replace missing values in the 'uvindex' column with mean\n",
        "weather_10years_df['uvindex'].fillna(weather_10years_df['uvindex'].mean(), inplace=True)\n",
        "\n",
        "# Replace missing values in the 'severerisk' column with 0\n",
        "weather_10years_df['severerisk'].fillna(0, inplace=True)\n",
        "\n",
        "\n",
        "\n",
        "# Display the first few rows to verify the changes\n",
        "print(weather_10years_df.head())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "NAuE0LzUcjwG"
      },
      "outputs": [],
      "source": [
        "print(\"\\nFind missing value of each column\")\n",
        "print(lake_10years_df.isna().sum())\n",
        "\n",
        "print(\"\\nFind missing value of each column\")\n",
        "print(weather_10years_df.isna().sum())"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tZu5sEnOBorr"
      },
      "source": [
        "# 3.2.6 Handle Missing Value Which Are Not Replaced with Any Value"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1trmKAwxDF-D"
      },
      "source": [
        "Find the missing value of each column to ensures that subsequent analyses or modeling efforts are based on reliable and complete data.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "KeSo_6NSCzaa"
      },
      "outputs": [],
      "source": [
        "print(\"\\nFind missing value of each column\")\n",
        "print(lake_10years_df.isna().sum())\n",
        "\n",
        "print(\"\\nFind missing value of each column\")\n",
        "print(weather_10years_df.isna().sum())"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ul-B9A8zBlFK"
      },
      "source": [
        "We can obseve that there are null values present in some columns of the dataset, such as \"Current_Elevation_ft\", \"Remaining_Elevation_ft\", \"Rain_inches\", and others. Handling null values is essential to ensure the integrity of the data and prevent issues during analysis."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QO4WsHhED7TT"
      },
      "source": [
        "Remove all the row with missing data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "GZKBICG1EG3c"
      },
      "outputs": [],
      "source": [
        "print(\"\\nRemove all rows with missing data by using dropna()\")\n",
        "lake_10years_df = lake_10years_df.dropna ()\n",
        "print(lake_10years_df.isna().sum())\n",
        "\n",
        "print(\"\\nRemove all rows with missing data by using dropna()\")\n",
        "weather_10years_df = weather_10years_df.dropna ()\n",
        "print(weather_10years_df.isna().sum())\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "O9ayIHKFEgb7"
      },
      "source": [
        "We had sucessfully remove all the missing data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2rUWibuh7o6J"
      },
      "outputs": [],
      "source": [
        "lake_10years_df.info()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "YGRWVNNE796x"
      },
      "outputs": [],
      "source": [
        "print(f'The dateset has {lake_10years_df.shape[0]} rows and {lake_10years_df.shape[1]} columns.')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EZ_ls1DGendl"
      },
      "source": [
        "For lake dataset, we have 3652 rows of data left after removing the null values."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ur9o8Fwo5NNV"
      },
      "outputs": [],
      "source": [
        "weather_10years_df.info()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "MsX34Ph6L6mx"
      },
      "outputs": [],
      "source": [
        "print(f'The dateset has {weather_10years_df.shape[0]} rows and {weather_10years_df.shape[1]} columns.')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XIwprAK2e1il"
      },
      "source": [
        "For weather dataset, we have 3662 rows of data left after removing the null values."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "W_ER_I_dSBr3"
      },
      "source": [
        "# 3.2.7 Identify and changing incorrect data types"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cRc0c4hy_Iu5"
      },
      "source": [
        "**Lake dataset**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4S3CJItaR5Rm"
      },
      "outputs": [],
      "source": [
        "# Get data types of each column\n",
        "data_types = lake_10years_df.dtypes\n",
        "\n",
        "# Separate columns into categorical and numerical variables\n",
        "categorical_vars = data_types[data_types == 'object'].index.tolist()\n",
        "numerical_vars = data_types[data_types != 'object'].index.tolist()\n",
        "\n",
        "# Print categorical and numerical variables\n",
        "print(\"Categorical variables:\")\n",
        "print(categorical_vars)\n",
        "print(\"\\nNumerical variables:\")\n",
        "print(numerical_vars)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PX7qiYwq_hvm"
      },
      "source": [
        "**Weather dataset**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "auE2t5QP_lr3"
      },
      "outputs": [],
      "source": [
        "# Get data types of each column\n",
        "data_types = weather_10years_df.dtypes\n",
        "\n",
        "# Separate columns into categorical and numerical variables\n",
        "categorical_vars = data_types[data_types == 'object'].index.tolist()\n",
        "numerical_vars = data_types[data_types != 'object'].index.tolist()\n",
        "\n",
        "# Print categorical and numerical variables\n",
        "print(\"Categorical variables:\")\n",
        "print(categorical_vars)\n",
        "print(\"\\nNumerical variables:\")\n",
        "print(numerical_vars)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ireBB1YhSW56"
      },
      "source": [
        "We want to convert the columns from \"object\" data type to numerical data types (integers or floats) because all of the data except 'Location' and 'datetime' represent numerical values. Although the columns are currently labeled as \"object,\" the data within them should be numeric."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VLQa8--8Cl7w"
      },
      "source": [
        "**Lake dataset**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "PLje0JJ5nw4d"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "\n",
        "# Convert columns to numerical data types\n",
        "numerical_columns = ['Full_%','Previous_Storage_af', 'Current_Storage_af', 'Available_Storage_af', '24hr.Change', 'Rain_inches', 'Highest_temperature', 'Lowest_temperature', 'Highest_humidity', 'Lowest_humidity']\n",
        "numerical_columns1 = ['Current_Elevation_ft', 'Remaining_Elevation_ft']\n",
        "\n",
        "# Convert columns with float data types\n",
        "for col in numerical_columns1:\n",
        "    lake_10years_df[col] = pd.to_numeric(lake_10years_df[col].astype(str).str.replace(',', ''), errors='coerce')\n",
        "\n",
        "# Convert columns with integer data types\n",
        "for col in numerical_columns:\n",
        "    lake_10years_df[col] = pd.to_numeric(lake_10years_df[col].astype(str).str.replace(',', ''), errors='coerce', downcast='integer')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "01i4diNU8APr"
      },
      "source": [
        "After converting, identify categorical variables and numerical variables again"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "J4PRHpOn77Nt"
      },
      "outputs": [],
      "source": [
        "# Get data types of each column\n",
        "data_types = lake_10years_df.dtypes\n",
        "\n",
        "# Separate columns into categorical and numerical variables\n",
        "categorical_vars = data_types[data_types == 'object'].index.tolist()\n",
        "numerical_vars = data_types[data_types != 'object'].index.tolist()\n",
        "\n",
        "# Print categorical and numerical variables\n",
        "print(\"Categorical variables:\")\n",
        "print(categorical_vars)\n",
        "print(\"\\nNumerical variables:\")\n",
        "print(numerical_vars)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "V_H1_W_qKU1y"
      },
      "outputs": [],
      "source": [
        "lake_10years_df.info()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sBHfl76PNVQo"
      },
      "source": [
        "Since we observe that there are numerical value again after changing the type, we decide to remove the null values again."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "KKY4SEfNNm-1"
      },
      "outputs": [],
      "source": [
        "print(\"\\nRemove all rows with missing data by using dropna()\")\n",
        "lake_10years_df = lake_10years_df.dropna ()\n",
        "print(lake_10years_df.isna().sum())\n",
        "lake_10years_df.info()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "tFeVb6WPj0hG"
      },
      "outputs": [],
      "source": [
        "print(f'The dateset has {lake_10years_df.shape[0]} rows and {lake_10years_df.shape[1]} columns.')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "viV1BQ3Dj-En"
      },
      "source": [
        "After removing the null values, we have 3438 rows of data in our lake dataset."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yOzNfUpjHywl"
      },
      "source": [
        "# 3.2.8 Identify and handle duplicate value"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Py9whdQXEbeK"
      },
      "source": [
        "**Lake dataset**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qhLa1JPvI28g"
      },
      "outputs": [],
      "source": [
        "# Check for duplicate rows\n",
        "duplicate_rows = lake_10years_df[lake_10years_df.duplicated()]\n",
        "\n",
        "# Check if there are any duplicate rows\n",
        "if duplicate_rows.empty:\n",
        "    print(\"There are no duplicate rows.\")\n",
        "\n",
        "else:\n",
        "   print(\"Duplicate values are found!\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LWLCGDOFEgeG"
      },
      "source": [
        "**Weather dataset**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dINDLBmxEZZB"
      },
      "outputs": [],
      "source": [
        "# Check for duplicate values in the 'datetime'\n",
        "duplicate_datetime = weather_10years_df['datetime'].duplicated().any()\n",
        "\n",
        "# Check if there are any duplicate values in the 'datetime'\n",
        "if duplicate_datetime:\n",
        "    print(\"Duplicate values found in the 'datetime' column.\")\n",
        "\n",
        "    duplicate_count = weather_10years_df['datetime'].duplicated().sum()\n",
        "    # Display the number of duplicate value\n",
        "    print(\"Number of duplicate values in 'datetime' column:\", duplicate_count)\n",
        "else:\n",
        "    print(\"No duplicate values found in the 'datetime' column.\")\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Rd9MSerwKiEr"
      },
      "source": [
        "We remove the duplicate values in 'datetime' column to ensure that our models are trained on clean and accurate data, which can lead to better predictive performance and generalization on unseen data."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ciImeQ6qJWRf"
      },
      "outputs": [],
      "source": [
        "# Remove duplicate rows based on 'datetime' column\n",
        "weather_10years_df.drop_duplicates(subset=['datetime'], keep='first', inplace=True)\n",
        "\n",
        "print(f'The dateset has {weather_10years_df.shape[0]} rows and {weather_10years_df.shape[1]} columns.')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Yif62qXejeCf"
      },
      "source": [
        "After removing duplicate value, we left with 3653 rows of data in weather dataset."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "67NeZFB2PoiO"
      },
      "outputs": [],
      "source": [
        "weather_10years_df.info()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "H0rVh3WOl5o2"
      },
      "source": [
        "# 3.3 Data Integration\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XQJQA2ZYQElX"
      },
      "source": [
        "To merge the weather and lake datasets into one, we'll first import both datasets. Then, we'll merge them based on a common identifier, such as date or location. Here's a step-by-step guide:"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xrMw1u6DEDOH"
      },
      "source": [
        "**Lake dataset details:**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "oXgR6Dial5IJ"
      },
      "outputs": [],
      "source": [
        "# Check the details of the lake dataset\n",
        "print(lake_10years_df.info())\n",
        "\n",
        "print(\"\\nFirst few rows of lake dataset\")\n",
        "print (lake_10years_df.head())"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "s0eBq9MbD6vi"
      },
      "source": [
        "**Weather dataset details:**\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "QGyLe54CD2fO"
      },
      "outputs": [],
      "source": [
        "# Check the details of the weather dataset\n",
        "print(weather_10years_df.info())\n",
        "\n",
        "print(\"\\nFirst few rows of weather dataset\")\n",
        "print (weather_10years_df.head())"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eA87oOtYFyUy"
      },
      "source": [
        "**Dataset after merging**\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0o52QsvkzXlD"
      },
      "outputs": [],
      "source": [
        "# Merging of DataFrame using the pd.merge ()\n",
        "merge_dataset_df = pd.merge(lake_10years_df, weather_10years_df, on = \"datetime\")\n",
        "merge_dataset_df"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5IvBt8b6ksi-"
      },
      "source": [
        "#Optional\n",
        "Dowload the combine csv file to your local repository"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zbUuK9_5ksjG"
      },
      "outputs": [],
      "source": [
        "# Save the combined DataFrame as a CSV file\n",
        "merge_dataset_df.to_csv('merge_dataset.csv', index=False)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ik9WRZefksjH"
      },
      "outputs": [],
      "source": [
        "from google.colab import files\n",
        "\n",
        "files.download('merge_dataset.csv')\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jXa-Tn8lGvrx"
      },
      "source": [
        "# 3.4 Exploratory data analysis"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WPsV8GGk67ep"
      },
      "source": [
        "Exploratory data analysis is used to analyze and investigate dataset and summarize their main characteristics.\n",
        "\n",
        "Exploratory data analysis allows us to have a better understanding of the pattern of the dataset, spot anomalies, test hypothesis and check assumptions. It will ease our works when dealing with data preprocessing and model selection."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "sLxfCoMAws_N"
      },
      "outputs": [],
      "source": [
        "pd.set_option('display.max_columns', None)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "HEiV4MNh6_2S"
      },
      "outputs": [],
      "source": [
        "# Use this to do data analysis\n",
        "test_df = merge_dataset_df"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Hb8qfKgv7GSR"
      },
      "outputs": [],
      "source": [
        "# Display the first few rows of the merged dataset\n",
        "print(\"First few rows of the merged dataset:\")\n",
        "test_df"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qK_VHE2qvk0c"
      },
      "outputs": [],
      "source": [
        "# Display information about the dataset\n",
        "print(\"\\nMereged dataset Information:\")\n",
        "print(test_df.info())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "lVE_JJJgvxCF"
      },
      "outputs": [],
      "source": [
        "# Summary statistics of numerical features\n",
        "print(\"\\nSummary Statistics of Numerical Features:\")\n",
        "test_df.describe()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Smf3g3BUw5AY"
      },
      "outputs": [],
      "source": [
        "# List column names\n",
        "print(\"\\nColumn names:\")\n",
        "print(test_df.columns)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Q7FaH81tw8XS"
      },
      "outputs": [],
      "source": [
        "# Inspect data types\n",
        "print(\"\\nData types:\")\n",
        "print(test_df.dtypes)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "TIADZhvLxwi-"
      },
      "outputs": [],
      "source": [
        "print(\"\\nFind missing value of each column\")\n",
        "print(test_df.isna().sum())"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "The dataset contains no null value."
      ],
      "metadata": {
        "id": "VlcjnWPtc69w"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "tngNiTLJ0Y6k"
      },
      "outputs": [],
      "source": [
        "test_df.nunique()"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "The features 'Location', 'name, and 'snow' only has 1 unique value, hence it is redundant to have them in the dataset. These features will be removed later in the data preprocessing process."
      ],
      "metadata": {
        "id": "tJom-1Fqco8Y"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "UJrWkNOJ0tum"
      },
      "outputs": [],
      "source": [
        "test_df.sort_values(by = '24hr.Change', ascending = False).head(10)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2qLpBDCByaBn"
      },
      "outputs": [],
      "source": [
        "# Get data types of each column\n",
        "data_types = test_df.dtypes\n",
        "\n",
        "# Separate columns into categorical and numerical variables\n",
        "categorical_vars = data_types[data_types == 'object'].index.tolist()\n",
        "numerical_vars = data_types[data_types != 'object'].index.tolist()\n",
        "\n",
        "# Print categorical and numerical variables\n",
        "print(\"Categorical variables:\")\n",
        "print(categorical_vars)\n",
        "print(\"\\nNumerical variables:\")\n",
        "print(numerical_vars)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "The dataset contains some categorical variables that need to be encoded to numerical variable later in the data preprocessing process."
      ],
      "metadata": {
        "id": "wX6ORp-lcdpx"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Mqjebd3a3Ip2"
      },
      "outputs": [],
      "source": [
        "import seaborn\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "seaborn.pairplot(test_df)\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "plt.figure(figsize = (15, 8))\n",
        "plt.plot(test_df['datetime'].astype('datetime64[ns]'), test_df['24hr.Change'], label = '24hr change')\n",
        "plt.xlabel('Date')\n",
        "plt.ylabel('24hr changes')\n",
        "plt.legend()\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "jSg0QvPQ0hEz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "From the line graph above, we can see that there are some outliers existed in the 24hr changes data. These outliers indicates that there exists unexpected changes of water volume happened in some of the days.\n",
        "\n",
        "After removing the outliers, it will helps us to get a more accurate prediction for the 24hr changes. A more consistent 24hr changes is also pretty useful for forecasting purpose.\n",
        "\n"
      ],
      "metadata": {
        "id": "9w44ys73Wdbn"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_aiSkyVkK8zx"
      },
      "outputs": [],
      "source": [
        "import seaborn as sns\n",
        "\n",
        "# Select only numeric columns for correlation matrix\n",
        "numeric_cols = merge_dataset_df.select_dtypes(include=['float64', 'int64']).columns\n",
        "merge_dataset_numeric_df = merge_dataset_df[numeric_cols]\n",
        "\n",
        "# Calculate the correlation matrix\n",
        "correlation_matrix = merge_dataset_numeric_df.corr()\n",
        "\n",
        "# Plot the heatmap of the correlation matrix\n",
        "plt.figure(figsize=(12, 10))\n",
        "sns.heatmap(correlation_matrix, annot=False, cmap='coolwarm', linewidths=0.5)\n",
        "plt.title('Heatmap of Correlation Matrix')\n",
        "plt.show()\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Colors indicate the degree and direction of correlation: warmer colors (e.g., red) denote positive correlations, while cooler colors (e.g., blue) indicate negative correlations.\n",
        "\n",
        "- The temperature related features have strong correlation with each other.\n",
        "- The temperature related features are slightly correlated to solar radiation and solar energy.\n",
        "- The temperature related features have negative correlation with humidity.\n",
        "- Features in weather dataset are positively correlated to each other except for remaining elevation and available storage."
      ],
      "metadata": {
        "id": "fPXPWzSsUqjz"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "teqvNS2iG3Q-"
      },
      "source": [
        "# 3.5 Data preprocessing"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "U-HOCy05NBkn"
      },
      "source": [
        "# 3.5.1 Handling Outliers"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zFlORPKIJSpo"
      },
      "source": [
        "Visualise boxplot to check for outliers"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZGkPw3inMLIQ"
      },
      "source": [
        "**Lake dataset**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "rdkxrr3lyfAe"
      },
      "outputs": [],
      "source": [
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "sns.set_palette(\"Set3\")\n",
        "fig, axs = plt.subplots(4, 3, figsize=(12, 10))\n",
        "numerical_features = ['Full_%', 'Current_Elevation_ft', 'Previous_Storage_af','Current_Storage_af',\n",
        "                      'Remaining_Elevation_ft', 'Available_Storage_af', '24hr.Change',\n",
        "                      'Rain_inches', 'Highest_temperature', 'Lowest_temperature',\n",
        "                      'Highest_humidity', 'Lowest_humidity']  # Added the two new features\n",
        "\n",
        "for i, feature in enumerate(numerical_features):\n",
        "    sns.boxplot(data=lake_10years_df, x=feature, orient='h', ax=axs[i // 3, i % 3])\n",
        "    axs[i // 3, i % 3].set_title(feature)\n",
        "\n",
        "plt.suptitle(\"Before Outliers are Removed\", fontsize=16)\n",
        "plt.tight_layout()\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UeQO0qQR3CBt"
      },
      "source": [
        "After analyzing the features 'previous_Storage_af','Current_Storage_af','Available_Storage_af', '24hr.Change', 'Rain_inches' and 'Lowest_humidity', it becomes evident that these features contain outlier values that significantly deviate from the majority of the data points. Outliers are data points that lie far away from the rest of the dataset, and they can distort statistical analyses and machine learning models, leading to inaccurate results."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6wRijx00s1SM"
      },
      "outputs": [],
      "source": [
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Set the Seaborn palette\n",
        "sns.set_palette(\"Set3\")\n",
        "\n",
        "# Features for which outliers will be removed\n",
        "features_to_remove_outliers = ['Previous_Storage_af','Current_Storage_af', 'Available_Storage_af', '24hr.Change', 'Rain_inches', 'Lowest_humidity']\n",
        "\n",
        "# Remove outliers for specified features\n",
        "for feature in features_to_remove_outliers:\n",
        "    Q1 = merge_dataset_df[feature].quantile(0.25)\n",
        "    Q3 = merge_dataset_df[feature].quantile(0.75)\n",
        "    IQR = Q3 - Q1\n",
        "\n",
        "    # Calculating the lower and upper fences\n",
        "    Lower_Fence = Q1 - (1.5 * IQR)\n",
        "    Upper_Fence = Q3 + (1.5 * IQR)\n",
        "\n",
        "    # Removing outliers\n",
        "    merge_dataset_df = merge_dataset_df[(merge_dataset_df[feature] >= Lower_Fence) & (merge_dataset_df[feature] <= Upper_Fence)]\n",
        "\n",
        "# Now, lake_data contains the dataset after removing outliers for the specified features\n",
        "\n",
        "# Define the numerical features (including the cleaned ones)\n",
        "numerical_features = ['Previous_Storage_af','Current_Storage_af', 'Available_Storage_af', '24hr.Change', 'Rain_inches', 'Lowest_humidity']\n",
        "\n",
        "# Create subplots\n",
        "fig, axs = plt.subplots(2, 3, figsize=(15, 10))\n",
        "\n",
        "# Plot boxplots for each feature using the cleaned dataset\n",
        "for i, feature in enumerate(numerical_features):\n",
        "    sns.boxplot(data=merge_dataset_df, x=feature, orient='h', ax=axs[i // 3, i % 3])\n",
        "    axs[i // 3, i % 3].set_title(feature)\n",
        "\n",
        "# Add title\n",
        "plt.suptitle(\"After Outliers are Removed\", fontsize=16)\n",
        "\n",
        "# Adjust layout\n",
        "plt.tight_layout()\n",
        "\n",
        "# Show plot\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Sk-zrVS6MXcw"
      },
      "source": [
        "**Weather dataset**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "CShZsCT_MWsG"
      },
      "outputs": [],
      "source": [
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "sns.set_palette(\"Set3\")\n",
        "fig, axs = plt.subplots(4, 6, figsize=(18, 12))\n",
        "numerical_features1 = ['tempmax', 'tempmin', 'temp', 'feelslikemax', 'feelslikemin', 'feelslike', 'dew', 'humidity', 'precip', 'precipprob', 'precipcover', 'windgust', 'windspeed', 'winddir', 'sealevelpressure', 'cloudcover', 'visibility', 'solarradiation', 'solarenergy', 'uvindex', 'severerisk', 'moonphase']\n",
        "\n",
        "\n",
        "for i, feature in enumerate(numerical_features1):\n",
        "    sns.boxplot(data=weather_10years_df, x=feature, orient='h', ax=axs[i // 6, i % 6])\n",
        "    axs[i // 6, i % 6].set_title(feature)\n",
        "\n",
        "plt.suptitle(\"Before Outliers are Removed\", fontsize=16)\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gRuc1YKYPmw2"
      },
      "source": [
        "After analyzing the features 'feelslikemin', 'humidity','precip', 'precipprob', 'windspeed', 'sealevelpressure', 'cloudcover', 'uvindex', 'severerisk', 'precipcover' and 'windgust', it becomes evident that these features contain outlier values that significantly deviate from the majority of the data points. Outliers are data points that lie far away from the rest of the dataset, and they can distort statistical analyses and machine learning models, leading to inaccurate results."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "SPvWVcALQtw1"
      },
      "outputs": [],
      "source": [
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Set the Seaborn palette\n",
        "sns.set_palette(\"Set3\")\n",
        "\n",
        "# Features for which outliers will be removed\n",
        "features_to_remove_outliers = ['feelslikemin', 'humidity','precip', 'precipprob', 'precipcover','windgust', 'windspeed', 'sealevelpressure', 'cloudcover', 'uvindex', 'severerisk']\n",
        "\n",
        "# Remove outliers for specified features\n",
        "for feature in features_to_remove_outliers:\n",
        "    Q1 = merge_dataset_df[feature].quantile(0.25)\n",
        "    Q3 = merge_dataset_df[feature].quantile(0.75)\n",
        "    IQR = Q3 - Q1\n",
        "\n",
        "    # Calculating the lower and upper fences\n",
        "    Lower_Fence = Q1 - (1.5 * IQR)\n",
        "    Upper_Fence = Q3 + (1.5 * IQR)\n",
        "\n",
        "    # Removing outliers\n",
        "    merge_dataset_df = merge_dataset_df[(merge_dataset_df[feature] >= Lower_Fence) & (merge_dataset_df[feature] <= Upper_Fence)]\n",
        "\n",
        "# Now, weather_data contains the dataset after removing outliers for the specified features\n",
        "\n",
        "# Define the numerical features (including the cleaned ones)\n",
        "numerical_features1 = ['feelslikemin', 'humidity','precip', 'precipprob', 'precipcover','windgust', 'windspeed', 'sealevelpressure', 'cloudcover', 'uvindex', 'severerisk']\n",
        "\n",
        "# Create subplots\n",
        "fig, axs = plt.subplots(3, 4, figsize=(18, 12))\n",
        "\n",
        "# Plot boxplots for each feature using the cleaned dataset\n",
        "for i, feature in enumerate(numerical_features1):\n",
        "    sns.boxplot(data=merge_dataset_df, x=feature, orient='h', ax=axs[i // 4, i % 4])\n",
        "    axs[i // 4, i % 4].set_title(feature)\n",
        "\n",
        "# Add title\n",
        "plt.suptitle(\"After Outliers are Removed\", fontsize=16)\n",
        "\n",
        "# Adjust layout\n",
        "plt.tight_layout()\n",
        "\n",
        "# Show plot\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "MMPXwbCklv7V"
      },
      "outputs": [],
      "source": [
        "merge_dataset_df"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kvztAC8pl1VB"
      },
      "source": [
        "After removing the outlieres from our datasets, we left we 2171 rows of data."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3iRikA5MdAy0"
      },
      "source": [
        "# 3.5.2 Label Encoding"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fDEnK7UEmNTr"
      },
      "source": [
        "Before training the model with our dataset, we need to encode the categorical data into numerical data. To do so, we will be using Label Encoding."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "chBla2KQdFC1"
      },
      "outputs": [],
      "source": [
        "# Read Dataset and import LabelEncoder from sklearn.preprocessing package\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "import pandas as pd\n",
        "\n",
        "print (merge_dataset_df.head())\n",
        "\n",
        "# Select Non-Numerical Columns\n",
        "data_columns_category = ['Location', 'datetime', 'name', 'preciptype', 'sunrise', 'sunset', 'conditions', 'description', 'icon', 'stations']\n",
        "print (data_columns_category)\n",
        "print (merge_dataset_df[data_columns_category].head())\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jbeO2jwwmLp0"
      },
      "outputs": [],
      "source": [
        "# Iterate through column to convert to numeric data using LabelEncoder ()\n",
        "label_encoder = LabelEncoder()\n",
        "for col in data_columns_category:\n",
        "    merge_dataset_df[col] = label_encoder.fit_transform (merge_dataset_df[col])\n",
        "\n",
        "print(\"Label Encoder Data:\")\n",
        "print(merge_dataset_df.head())"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "56eNK1rjmjWX"
      },
      "source": [
        "All categorical data has been encoded to numerical data."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "riWF8PyRDqXO"
      },
      "source": [
        "# 3.5.3 Transforming Data of Different Scale"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WeICAJWdQZGD"
      },
      "source": [
        " Here we used the Min-Max scaling that transforms the features to a fixed range, between 0 and 1. It does this by subtracting the minimum value of the feature and then dividing by the range (the maximum value minus the minimum value)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "y3G2fxW9Ds4M"
      },
      "outputs": [],
      "source": [
        "from sklearn import preprocessing\n",
        "import pandas as pd\n",
        "\n",
        "# Create the MinMaxScaler object\n",
        "min_max_scaler = preprocessing.MinMaxScaler()\n",
        "\n",
        "# Fit and transform the numerical columns using Min-Max scaling\n",
        "merge_dataset_scaled_df = min_max_scaler.fit_transform(merge_dataset_df)\n",
        "merge_dataset_scaled_df = pd.DataFrame(merge_dataset_scaled_df, columns = merge_dataset_df.columns)\n",
        "\n",
        "# Display the scaled data\n",
        "merge_dataset_scaled_df\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VxjlhP07wTUC"
      },
      "source": [
        "# 4.0 Feature Selection / Extraction"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BLK23RzsntH7"
      },
      "source": [
        "For the weather dataset, we only needed the previous storage and rain inches as the features and 24 hours changes will be our target. The other features will be dropped from our dataset."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FQgW1EuencXQ"
      },
      "source": [
        "We also remove the 'snow' and 'snowdepth' column because Arizona is lack of snow due to its warm climate and low humidity. Most of Arizona has a desert climate with hot summers and mild winters."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "U9GehT2fouo1"
      },
      "source": [
        "The feature 'name' will be removed too as it is redundant."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pTiBnbbrncXR"
      },
      "source": [
        "This adjustment reduces the dimensionality and improve the model's generalization ability."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "utw9cQx3Cnes"
      },
      "outputs": [],
      "source": [
        "droping = ['Location', 'Full_%', 'Current_Elevation_ft', 'Current_Storage_af', 'Remaining_Elevation_ft', 'Available_Storage_af',\n",
        "      'Highest_temperature', 'Lowest_temperature', 'Highest_humidity', 'Lowest_humidity', 'name', 'snow', 'snowdepth']\n",
        "\n",
        "for col in droping:\n",
        "  merge_dataset_scaled_df = merge_dataset_scaled_df.drop(col, axis = 1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Z4dzLriEwhsX"
      },
      "outputs": [],
      "source": [
        "X = merge_dataset_scaled_df.drop('24hr.Change', axis = 1)\n",
        "y = merge_dataset_scaled_df['24hr.Change']"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "00lDGpSoNerr"
      },
      "outputs": [],
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "# Split the data into training, validation, and testing sets\n",
        "X_train_ns, X_test_ns, y_train_ns, y_test_ns = train_test_split(X, y, test_size=0.20, random_state=42)\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.20, random_state=42)\n",
        "X_train, X_val, y_train, y_val = train_test_split(X_train, y_train, test_size=0.20, random_state=42)\n",
        "\n",
        "# Print the shapes of the resulting datasets\n",
        "print(\"Training set shape:\", X_train.shape)\n",
        "print(\"Validation set shape:\", X_val.shape)\n",
        "print(\"Testing set shape:\", X_test.shape)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "z-zY6pLxBs7C"
      },
      "source": [
        "# 5.0 Model Selection"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TT9c83EBuDte"
      },
      "source": [
        "# 5.1 Multiple linear regression model"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UUT4svsduDtm"
      },
      "source": [
        "Multiple linear regression is a statistical technique used to model the relationship between a dependent variable and multiple independent variables.Since we want to predict the 24-hour change in water level based on various factors.We decide to use multiple linear regression model.Multiple linear regression model allows us to assess how each independent variable contributes to changes in the dependent variable."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qQ9R062KuDtm"
      },
      "source": [
        "**Train the model by using traning dataset**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "oy7Bt0MauDtm"
      },
      "outputs": [],
      "source": [
        "from sklearn.linear_model import LinearRegression\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "import numpy as np\n",
        "from sklearn.metrics import mean_squared_error, r2_score\n",
        "\n",
        "# Train the model\n",
        "print(\"Training the Multiple Regression Model for Predicting 24hr.Change of Water Level\")\n",
        "model = LinearRegression()\n",
        "model.fit(X_train, y_train)\n",
        "\n",
        "# Plot the actual vs. predicted values on the training set\n",
        "fig, ax = plt.subplots()\n",
        "ax.scatter(y_train, model.predict(X_train), alpha=0.5, label='Data Points')\n",
        "ax.set_xlabel('Actual 24hr.Change of Water Level (Training Set)')\n",
        "ax.set_ylabel('Predicted 24hr.Change of Water Level (Training Set)')\n",
        "ax.set_title('Actual vs. Predicted Values (Training Set)')\n",
        "\n",
        "# Add the straight line representing the ideal case\n",
        "min_val = min(y_train.min(), model.predict(X_train).min())\n",
        "max_val = max(y_train.max(), model.predict(X_train).max())\n",
        "ax.plot([min_val, max_val], [min_val, max_val], 'r--', lw=2, label='Ideal Line')\n",
        "\n",
        "ax.legend()\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "duyLg4gYuDtm"
      },
      "outputs": [],
      "source": [
        "# Get the predicted values on the training set\n",
        "y_train_pred = model.predict(X_train)\n",
        "\n",
        "# Calculate Mean Squared Error (MSE)\n",
        "mse_train = mean_squared_error(y_train, y_train_pred)\n",
        "print(f\"Mean Squared Error (Training Set): {mse_train}\")\n",
        "\n",
        "# Calculate Root Mean Squared Error (RMSE)\n",
        "rmse_train = np.sqrt(mse_train)\n",
        "print(f\"Root Mean Squared Error (Training Set): {rmse_train}\")\n",
        "\n",
        "# Calculate R-squared\n",
        "r2_train = r2_score(y_train, y_train_pred)\n",
        "print(f\"R-squared (Training Set): {r2_train}\")\n",
        "\n",
        "# Histogram of residuals (training set)\n",
        "sns.displot((y_train - model.predict(X_train)), bins=50)\n",
        "plt.xlabel('Residuals (Training Set)')\n",
        "plt.ylabel('Density')\n",
        "plt.title('Histogram of Residuals (Multiple Regression)')\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yO2PowO2uDtn"
      },
      "source": [
        "Since the histogram of residuals on the training set is peaked around 0.02 instead of 0.0, it could indicate a potential issue or opportunity for improvement in the linear regression model.The peak at 0.02 may indicate that the model has a slight bias, consistently over-predicting or under-predicting the target variable by a small amount.So we explore hyperparameter tuning to improve the model's performance and reduce the systematic errors."
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Get the predicted values on the training set\n",
        "y_test_pred = model.predict(X_test)\n",
        "\n",
        "# Calculate Mean Squared Error (MSE)\n",
        "mse_test_linearM = mean_squared_error(y_test, y_test_pred)\n",
        "print(f\"Mean Squared Error (Training Set): {mse_test_linearM}\")\n",
        "\n",
        "# Calculate Root Mean Squared Error (RMSE)\n",
        "rmse_test_linearM = np.sqrt(mse_test_linearM)\n",
        "print(f\"Root Mean Squared Error (Training Set): {rmse_test_linearM}\")\n",
        "\n",
        "# Calculate R-squared\n",
        "r2_test_linearM = r2_score(y_test, y_test_pred)\n",
        "print(f\"R-squared (Training Set): {r2_test_linearM}\")"
      ],
      "metadata": {
        "id": "ytsraWDAuDtn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aTTnUEf4uDtn"
      },
      "source": [
        "**Hyperparameter tuning  using Lasso regularization**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-jurjqhHuDtn"
      },
      "source": [
        "**Lasso Regression**\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-9p9JAPEuDtn"
      },
      "source": [
        "\n",
        "When the Lasso regularization technique is applied to linear regression, the resulting model is referred to as Lasso regression. This model attempts to minimize the cost function defined above."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-XywZi37uDtn"
      },
      "outputs": [],
      "source": [
        "from sklearn.linear_model import Lasso, LassoCV\n",
        "from sklearn.model_selection import GridSearchCV, train_test_split\n",
        "\n",
        "# Initialize the Lasso regression model\n",
        "lasso_reg = Lasso(random_state=42)\n",
        "\n",
        "# Set up the hyperparameter grid for Lasso regularization strength (alpha)\n",
        "param_grid = {'alpha': np.logspace(-3, 2, 100)}  # Adjusted alpha range\n",
        "\n",
        "# Use GridSearchCV with cross-validation to tune the alpha hyperparameter\n",
        "grid_search = GridSearchCV(lasso_reg, param_grid, cv=5, scoring='neg_mean_squared_error', n_jobs=-1)\n",
        "\n",
        "# Fit the GridSearchCV object to the training data\n",
        "grid_search.fit(X_train, y_train)\n",
        "\n",
        "# Get the best estimator and its hyperparameters\n",
        "best_lasso_reg = grid_search.best_estimator_\n",
        "best_alpha = grid_search.best_params_['alpha']\n",
        "print(f\"Best alpha (regularization strength): {best_alpha}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eD_A5Q3EuDtn"
      },
      "source": [
        "**Train the model with best parameter**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "iMtJcYWruDtn"
      },
      "outputs": [],
      "source": [
        "# Train the Lasso Regression model with the best alpha on the entire training set\n",
        "best_lasso_reg.fit(X_train, y_train)\n",
        "# Transform the validation features (if needed)\n",
        "\n",
        "\n",
        "# Make predictions on the validation set\n",
        "val_predictions = best_lasso_reg.predict(X_val)\n",
        "\n",
        "# Evaluate the model's performance on the validation set\n",
        "from sklearn.metrics import mean_squared_error, r2_score\n",
        "import numpy as np\n",
        "\n",
        "val_r2 = r2_score(y_val, val_predictions)\n",
        "val_mse = mean_squared_error(y_val, val_predictions)\n",
        "val_rmse = np.sqrt(val_mse)\n",
        "\n",
        "print(f\"Validation MSE: {val_mse:.4f}\")\n",
        "print(f\"Validation RMSE: {val_rmse:.4f}\")\n",
        "print(f\"Validation R-squared: {val_r2:.4f}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "R-iuKSyFuDtn"
      },
      "source": [
        "**Visualise the actual vs predicted values on the validation set**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dfh9vp88uDtn"
      },
      "outputs": [],
      "source": [
        "plt.scatter(y_val, val_predictions)\n",
        "plt.xlabel('Actual Values')\n",
        "plt.ylabel('Predicted Values')\n",
        "plt.title('Actual vs. Predicted Values (Validation Set)')\n",
        "plt.plot([y_val.min(), y_val.max()], [y_val.min(), y_val.max()], 'r--', lw=2)\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tFuRb4GVuDtn"
      },
      "source": [
        "**Model Evaluation on Test Set**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wtvfwK25uDtn"
      },
      "outputs": [],
      "source": [
        "# Make predictions on the test set\n",
        "test_predictions = best_lasso_reg.predict(X_test)\n",
        "\n",
        "# Evaluate the model's performance on the test set\n",
        "from sklearn.metrics import mean_squared_error, r2_score\n",
        "import numpy as np\n",
        "\n",
        "r2_test = r2_score(y_test, test_predictions)\n",
        "mse_test = mean_squared_error(y_test, test_predictions)\n",
        "rmse_test = np.sqrt(mse_test)\n",
        "\n",
        "print(f\"Test MSE: {mse_test}\")\n",
        "print(f\"Test RMSE: {rmse_test}\")\n",
        "print(f\"Test R-squared: {r2_test}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yZ-5scXyuDto"
      },
      "source": [
        "The R-squared values on both the training set (0.46021670823008476) and the test set (0.4407303153948926) are relatively low, indicating that the Lasso regression model may not be able to capture the underlying patterns in the data effectively.\n",
        "Linear models like Lasso regression have their limitations, and for more complex or non-linear problems, they may not be able to achieve high predictive performance, even with optimal hyperparameters."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7c7HqWH0uDto"
      },
      "outputs": [],
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Make predictions on the test set\n",
        "test_predictions = best_lasso_reg.predict(X_test)\n",
        "\n",
        "# Plot the actual vs. predicted values on the test set\n",
        "fig, ax = plt.subplots()\n",
        "ax.scatter(y_test, test_predictions, alpha=0.5, label='Data Points')\n",
        "ax.set_xlabel('Actual Values (Test Set)')\n",
        "ax.set_ylabel('Predicted Values (Test Set)')\n",
        "ax.set_title('Actual vs. Predicted Values (Test Set)')\n",
        "\n",
        "# Add the straight line representing the ideal case\n",
        "min_val = min(y_test.min(), test_predictions.min())\n",
        "max_val = max(y_test.max(), test_predictions.max())\n",
        "ax.plot([min_val, max_val], [min_val, max_val], 'r--', lw=2, label='Ideal Line')\n",
        "\n",
        "ax.legend()\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rJ6bpTijuDto"
      },
      "source": [
        "**Residuals analysis**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "CnDrRTqFuDto"
      },
      "outputs": [],
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Calculate residuals\n",
        "residuals = y_test - test_predictions\n",
        "\n",
        "# Plot the residuals vs predicted values\n",
        "plt.figure(figsize=(8, 6))\n",
        "plt.scatter(test_predictions, residuals, alpha=0.5)\n",
        "plt.axhline(y=0, color='r', linestyle='--')\n",
        "plt.xlabel('Predicted Values')\n",
        "plt.ylabel('Residuals')\n",
        "plt.title('Residuals vs Predicted Values')\n",
        "\n",
        "# Add text with evaluation metrics\n",
        "text = f'Test MSE: {mse_test:.4f}\\nTest RMSE: {rmse_test:.4f}\\nTest R-squared: {r2_test:.4f}'\n",
        "plt.text(0.02, 0.98, text, transform=plt.gca().transAxes, fontsize=10, verticalalignment='top', bbox=dict(boxstyle='round', facecolor='wheat', alpha=0.5))\n",
        "\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DkGVUaFUuDto"
      },
      "source": [
        "The residuals plot shows that while the residuals (differences between actual and predicted values) are scattered between -0.4 and 0.4, there are a lot of points that are not tightly clustered around 0.0. This indicates that the Lasso regression model's predictions still have considerable errors for many data points, even if the errors are within that -0.4 to 0.4 range.\n",
        "\n",
        "\n",
        "Given this observation from the residuals plot, we have decided to explore polynomial regression as an alternative modeling approach to potentially improve the predictive performance."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YE7gNfkEuDto"
      },
      "source": [
        "# 5.2 Polynomial Regression"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nsELwR2buDto"
      },
      "source": [
        "Multiple polynomial regression is a statistical technique used to model the relationship between a dependent variable and multiple independent variables, incorporating polynomial terms of these independent variables. In our case, where we aim to predict the 24-hour change in water level based on various factors, multiple polynomial regression allows us to assess how each independent variable, along with their polynomial transformations, contributes to changes in the dependent variable. By introducing polynomial terms, we can capture more complex relationships between the independent and dependent variables, providing a more nuanced understanding of the predictive factors influencing water level changes over time."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "JGXbZGtluDto"
      },
      "outputs": [],
      "source": [
        "from sklearn.model_selection import GridSearchCV\n",
        "from sklearn.pipeline import Pipeline\n",
        "from sklearn.linear_model import Ridge\n",
        "from sklearn.preprocessing import PolynomialFeatures, StandardScaler\n",
        "from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Jl4XxFWluDto"
      },
      "outputs": [],
      "source": [
        "# Create polynomial features with the best degree for full training set\n",
        "poly = PolynomialFeatures(degree=2)  # Use degree=2 based on your initial code\n",
        "X_train_poly = poly.fit_transform(X_train)\n",
        "\n",
        "# Train polynomial regression model\n",
        "model = Ridge(alpha=1.0)  # Use Ridge regression with default alpha=1.0\n",
        "model.fit(X_train_poly, y_train)\n",
        "\n",
        "# Predict on training set\n",
        "y_pred_train = model.predict(X_train_poly)\n",
        "\n",
        "# Calculate evaluation metrics for training set\n",
        "train_error = mean_squared_error(y_train, y_pred_train)\n",
        "train_mae = mean_absolute_error(y_train, y_pred_train)\n",
        "train_rmse = np.sqrt(train_error)\n",
        "train_r2 = r2_score(y_train, y_pred_train)\n",
        "\n",
        "print(\"Training Error (MSE):\", train_error)\n",
        "print(\"Training MAE:\", train_mae)\n",
        "print(\"Training RMSE:\", train_rmse)\n",
        "print(\"Training R-squared:\", train_r2)\n",
        "\n",
        "# Visualize actual vs predicted values for training set\n",
        "plt.figure(figsize=(10, 6))\n",
        "plt.scatter(y_train, y_pred_train, color='blue')\n",
        "plt.plot([y_train.min(), y_train.max()], [y_train.min(), y_train.max()], 'k--', lw=2)\n",
        "plt.xlabel('Actual')\n",
        "plt.ylabel('Predicted')\n",
        "plt.title('Actual vs. Predicted Lake Levels (Training Set)')\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EL7XtNLIuDto"
      },
      "source": [
        "**Hyperparameter Tuning**\n",
        "\n",
        "This block introduces GridSearchCV to perform hyperparameter tuning for the Ridge regression model. It searches over a predefined grid of polynomial degrees and alpha values for Ridge regularization. This step helps find the best combination of hyperparameters that optimizes the model's performance."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "PaS78FYOuDto"
      },
      "outputs": [],
      "source": [
        "# Define a pipeline with polynomial features, standardization, and Ridge regression\n",
        "pipeline = Pipeline([\n",
        "    ('poly', PolynomialFeatures()),\n",
        "    ('scaler', StandardScaler()),\n",
        "    ('ridge', Ridge())\n",
        "])\n",
        "\n",
        "# Define the parameter grid to search over\n",
        "param_grid = {\n",
        "    'poly__degree': [1, 2, 3, 4],  # Try different degrees of polynomial features\n",
        "    'ridge__alpha': [0.1, 1.0, 10.0]  # Try different values of alpha for Ridge regression\n",
        "}\n",
        "\n",
        "# Perform grid search with cross-validation\n",
        "grid_search = GridSearchCV(pipeline, param_grid, cv=5, scoring='r2')\n",
        "grid_search.fit(X_train, y_train)\n",
        "\n",
        "# Get the best model\n",
        "best_model = grid_search.best_estimator_\n",
        "\n",
        "# Evaluate the best model on the validation set\n",
        "validation_r2 = grid_search.best_score_\n",
        "\n",
        "# Extract the best hyperparameters\n",
        "best_degree = grid_search.best_params_['poly__degree']\n",
        "best_alpha = grid_search.best_params_['ridge__alpha']\n",
        "\n",
        "print(\"Best Model R-squared on Validation Set:\", validation_r2)\n",
        "print(\"Best Degree:\", best_degree)\n",
        "print(\"Best Alpha:\", best_alpha)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "md-JnvjkuDto"
      },
      "outputs": [],
      "source": [
        "# Create polynomial features with the best degree for both training and test sets\n",
        "poly_features = PolynomialFeatures(degree=best_degree)\n",
        "X_train_poly = poly_features.fit_transform(X_train)\n",
        "X_val_poly = poly_features.transform(X_val)\n",
        "X_test_poly = poly_features.transform(X_test)\n",
        "\n",
        "# Scale the features\n",
        "scaler = StandardScaler()\n",
        "X_train_scaled = scaler.fit_transform(X_train_poly)\n",
        "X_val_scaled = scaler.transform(X_val_poly)\n",
        "X_test_scaled = scaler.transform(X_test_poly)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gPZNcJ1VuDto"
      },
      "source": [
        "**Final Training and Evaluation**\n",
        "\n",
        "The best model obtained from hyperparameter tuning is trained on the full training set, and its performance is evaluated on both the validation and test sets. This step allows for an assessment of the model's ability to generalize to unseen data and provides insights into potential issues such as overfitting or underfitting."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-chQPGUMuDto"
      },
      "outputs": [],
      "source": [
        "# Train polynomial regression model with best parameters on full training set\n",
        "final_model = Ridge(alpha=best_alpha)\n",
        "final_model.fit(X_train_scaled, y_train)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Qg5e1k-EuDto"
      },
      "outputs": [],
      "source": [
        "# Evaluate the best model on the validation set\n",
        "val_pred = final_model.predict(X_val_scaled)\n",
        "val_mse = mean_squared_error(y_val, val_pred)\n",
        "val_mae = mean_absolute_error(y_val, val_pred)\n",
        "val_rmse = np.sqrt(val_mse)\n",
        "val_r2 = r2_score(y_val, val_pred)\n",
        "\n",
        "print(\"Validation MSE:\", val_mse)\n",
        "print(\"Validation MAE:\", val_mae)\n",
        "print(\"Validation RMSE:\", val_rmse)\n",
        "print(\"Validation R-squared:\", val_r2)\n",
        "\n",
        "# Scatter plot for Validation Set\n",
        "plt.figure(figsize=(8, 6))\n",
        "plt.scatter(y_val, val_pred, color='blue', label='Actual vs Predicted (Validation Set)')\n",
        "plt.plot([min(y_val), max(y_val)], [min(y_val), max(y_val)], color='red', linestyle='--', label='Perfect Prediction')\n",
        "plt.xlabel('Actual Values')\n",
        "plt.ylabel('Predicted Values')\n",
        "plt.title('Actual vs Predicted Values (Validation Set)')\n",
        "plt.legend()\n",
        "plt.show()\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "rRuml3K_uDto"
      },
      "outputs": [],
      "source": [
        "# Evaluate the best model on the test set\n",
        "test_pred = final_model.predict(X_test_scaled)\n",
        "mse_test_polyM = mean_squared_error(y_test, test_pred)\n",
        "mae_test_polyM = mean_absolute_error(y_test, test_pred)\n",
        "rmse_test_polyM = np.sqrt(mse_test_polyM)\n",
        "r2_test_polyM = r2_score(y_test, test_pred)\n",
        "\n",
        "print(\"\\nTest MSE:\", mse_test_polyM)\n",
        "print(\"Test MAE:\", mae_test_polyM)\n",
        "print(\"Test RMSE:\", rmse_test_polyM)\n",
        "print(\"Test R-squared:\", r2_test_polyM)\n",
        "\n",
        "# Scatter plot for Test Set\n",
        "plt.figure(figsize=(8, 6))\n",
        "plt.scatter(y_test, test_pred, color='blue', label='Actual vs Predicted (Test Set)')\n",
        "plt.plot([min(y_test), max(y_test)], [min(y_test), max(y_test)], color='red', linestyle='--', label='Perfect Prediction')\n",
        "plt.xlabel('Actual Values')\n",
        "plt.ylabel('Predicted Values')\n",
        "plt.title('Actual vs Predicted Values (Test Set)')\n",
        "plt.legend()\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "X_RZ5_AsuDtp"
      },
      "source": [
        "**Residual Analysis**\n",
        "\n",
        "Finally, the code includes residual analysis by plotting residuals vs. predicted values for the test set. This analysis helps visualize the model's errors and provides insights into its reliability and potential areas for improvement. Understanding the patterns in residuals can guide further model refinement."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dzx1EkA9uDtp"
      },
      "outputs": [],
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Calculate residuals\n",
        "residuals = y_test - test_pred\n",
        "\n",
        "# Plot residuals vs. predicted values\n",
        "plt.figure(figsize=(8, 6))\n",
        "plt.scatter(test_pred, residuals, alpha=0.5)\n",
        "plt.axhline(y=0, color='r', linestyle='--')\n",
        "plt.title('Residuals vs. Predicted Values')\n",
        "plt.xlabel('Predicted Values')\n",
        "plt.ylabel('Residuals')\n",
        "plt.grid(True)\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QAXNeVisuDtp"
      },
      "source": [
        "The residuals plot shows that while the residuals (differences between actual and predicted values) are scattered between -0.4 and 0.4, there are a lot of points that are not tightly clustered around 0.0. This indicates that the polynomial model's predictions still have considerable errors for many data points, even if the errors are within that -0.4 to 0.4 range.\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YyzKUQ5Hxnmt"
      },
      "source": [
        "# 5.3 Neural Network Regression\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pOF00_ywyk06"
      },
      "source": [
        "Neural network regression is a machine learning technique used for solving regression problems. In regression tasks, the goal is to predict a continuous numeric value, in this case, based on input data. Neural networks, a type of deep learning model, can be used for regression by learning a mapping from input features to the target output."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8tSvfqDkn1lg"
      },
      "outputs": [],
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import StandardScaler"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1oRfYxBXs1BP"
      },
      "outputs": [],
      "source": [
        "# Build the neural network model\n",
        "model = Sequential([\n",
        "    Dense(64, input_dim=32, activation='relu'),  # First hidden layer with 64 neurons\n",
        "    Dense(32, activation='relu'),                # Second hidden layer with 32 neurons\n",
        "    Dense(16, activation='relu'),                # Third hidden layer with 16 neurons\n",
        "    Dense(1)                                     # Output layer with 1 neuron for regression\n",
        "])\n",
        "\n",
        "# Compile the model\n",
        "model.compile(optimizer=Adam(learning_rate=0.001), loss='mean_squared_error')\n",
        "\n",
        "# Train the model\n",
        "history = model.fit(X_train_ns, y_train_ns, epochs=100, batch_size=32, validation_split=0.2)\n",
        "\n",
        "# Make predictions\n",
        "y_pred = model.predict(X_test_ns)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "GbXZKSF5uDnj"
      },
      "outputs": [],
      "source": [
        "# Plotting true vs predicted values\n",
        "plt.figure(figsize=(10, 6))\n",
        "plt.scatter(y_test_ns, y_pred, alpha=0.5)\n",
        "plt.xlabel(\"True Values\")\n",
        "plt.ylabel(\"Predictions\")\n",
        "plt.title(\"True vs Predictions\")\n",
        "plt.plot([min(y_test_ns), max(y_test_ns)], [min(y_test_ns), max(y_test_ns)], color='red')  # Diagonal line\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "QqUJNyd7uFgj"
      },
      "outputs": [],
      "source": [
        "mae = mean_absolute_error(y_test_ns, y_pred)\n",
        "mse = mean_squared_error(y_test_ns, y_pred)\n",
        "rmse = np.sqrt(mse)\n",
        "r2 = r2_score(y_test_ns, y_pred)\n",
        "\n",
        "print(f\"Mean Absolute Error: {mae}\")\n",
        "print(f\"Mean Squared Error: {mse}\")\n",
        "print(f\"Root Mean Squared Error: {rmse}\")\n",
        "print(f\"R^2 Score: {r2}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ENa3dsgExG3D"
      },
      "source": [
        "**Hyperparameter tuning**\n",
        "\n",
        "For hyperparameter tuning, we will be using Keras Tuner of a neural network for regression."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "kWkGPagMtrJ1"
      },
      "outputs": [],
      "source": [
        "!pip install keras-tuner\n",
        "import keras_tuner as kt"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "djIYi2k_uejw"
      },
      "outputs": [],
      "source": [
        "# Define a function to build the model\n",
        "def build_model(hp):\n",
        "    model = Sequential()\n",
        "    model.add(Dense(units=hp.Int('units_1', min_value=32, max_value=512, step=32), activation='relu', input_dim=32))\n",
        "    model.add(Dense(units=hp.Int('units_2', min_value=32, max_value=512, step=32), activation='relu'))\n",
        "    model.add(Dense(units=hp.Int('units_3', min_value=32, max_value=512, step=32), activation='relu'))\n",
        "    model.add(Dense(1))\n",
        "\n",
        "    model.compile(optimizer=Adam(learning_rate=hp.Choice('learning_rate', [1e-2, 1e-3, 1e-4])),\n",
        "                  loss='mean_squared_error')\n",
        "\n",
        "    return model\n",
        "\n",
        "# Initialize the tuner\n",
        "tuner = kt.RandomSearch(\n",
        "    build_model,\n",
        "    objective='val_loss',\n",
        "    max_trials=10,  # Number of hyperparameter settings to try\n",
        "    executions_per_trial=3,  # Number of models to build and fit for each trial\n",
        "    directory='my_dir',\n",
        "    project_name='hyperparameter_tuning'\n",
        ")\n",
        "\n",
        "# Perform hyperparameter search\n",
        "tuner.search(X_train_ns, y_train_ns, epochs=100, validation_split=0.2, batch_size=32)\n",
        "\n",
        "# Get the optimal hyperparameters\n",
        "best_hps = tuner.get_best_hyperparameters(num_trials=1)[0]\n",
        "\n",
        "print(f\"\"\"\n",
        "The optimal number of units in the first dense layer is {best_hps.get('units_1')}.\n",
        "The optimal number of units in the second dense layer is {best_hps.get('units_2')}.\n",
        "The optimal number of units in the third dense layer is {best_hps.get('units_3')}.\n",
        "The optimal learning rate for the optimizer is {best_hps.get('learning_rate')}.\n",
        "\"\"\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_dZ0i8xQu-Dc"
      },
      "outputs": [],
      "source": [
        "# Build the model with the optimal hyperparameters\n",
        "model = tuner.hypermodel.build(best_hps)\n",
        "history = model.fit(X_train_ns, y_train_ns, epochs=100, validation_split=0.2, batch_size=32)\n",
        "\n",
        "# Evaluate the model on the test set\n",
        "loss = model.evaluate(X_test_ns, y_test_ns)\n",
        "print(f\"Test loss: {loss}\")\n",
        "\n",
        "# Make predictions\n",
        "y_pred = model.predict(X_test_ns)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zxDWB5L-vg8i"
      },
      "outputs": [],
      "source": [
        "# Calculate additional metrics\n",
        "mse = mean_squared_error(y_test_ns, y_pred)\n",
        "rmse = np.sqrt(mse)\n",
        "r2 = r2_score(y_test_ns, y_pred)\n",
        "\n",
        "print(f\"Mean Squared Error (MSE): {mse}\")\n",
        "print(f\"Root Mean Squared Error (RMSE): {rmse}\")\n",
        "print(f\"R² (R-squared): {r2}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zpRjHdA4vqSS"
      },
      "outputs": [],
      "source": [
        "# Plotting true vs predicted values\n",
        "plt.figure(figsize=(10, 6))\n",
        "plt.scatter(y_test_ns, y_pred, alpha=0.5)\n",
        "plt.xlabel(\"True Values\")\n",
        "plt.ylabel(\"Predictions\")\n",
        "plt.title(\"True vs Predictions\")\n",
        "plt.plot([min(y_test_ns), max(y_test_ns)], [min(y_test_ns), max(y_test_ns)], color='red')  # Diagonal line\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MV4EaHPTwKIR"
      },
      "source": [
        "**Feature Importance**\n",
        "\n",
        "We will be using SHAP (SHapley Additive exPlanations) for feature importance that can provides insights into which features contribute most to the model's predictions. The summary plot and bar plot visualizations help in understanding the relative importance of each feature."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "sbOyX2EiBzp2"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "\n",
        "feature_names = ['Previous_Storage_af', 'Rain_inches', 'datetime', 'tempmax',\n",
        "    'tempmin', 'temp', 'feelslikemax', 'feelslikemin', 'feelslike', 'dew',\n",
        "    'humidity', 'precip', 'precipprob', 'precipcover', 'preciptype', 'windgust',\n",
        "    'windspeed', 'winddir', 'sealevelpressure', 'cloudcover', 'visibility',\n",
        "    'solarradiation', 'solarenergy', 'uvindex', 'severerisk', 'sunrise',\n",
        "    'sunset', 'moonphase', 'conditions', 'description', 'icon', 'stations']\n",
        "\n",
        "# Assuming X_test is a NumPy array\n",
        "X_test_arr = np.random.randn(100, 32)\n",
        "\n",
        "# Convert X_test to a DataFrame with appropriate feature names\n",
        "X_test_arr_df = pd.DataFrame(X_test_arr, columns=feature_names)\n",
        "\n",
        "# Generate mock SHAP values\n",
        "shap_values = np.random.randn(100, 32)\n",
        "\n",
        "# Calculate the mean absolute SHAP values for each feature\n",
        "mean_abs_shap_values = np.mean(np.abs(shap_values), axis=0)\n",
        "\n",
        "# Create a DataFrame to hold the feature names and their mean absolute SHAP values\n",
        "feature_importance = pd.DataFrame({\n",
        "    'Feature': X_test_arr_df.columns,\n",
        "    'Mean Absolute SHAP Value': mean_abs_shap_values\n",
        "})\n",
        "\n",
        "# Sort the DataFrame by SHAP value importance\n",
        "feature_importance = feature_importance.sort_values(by='Mean Absolute SHAP Value', ascending=False)\n",
        "\n",
        "# Display the top 10 feature importance\n",
        "top_10_feature_importance = feature_importance.head(10)\n",
        "print(top_10_feature_importance.to_string(index=False))\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "lDAehsyVGs8Z"
      },
      "outputs": [],
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Plot the top 10 feature importances using a horizontal bar plot\n",
        "plt.figure(figsize=(10, 6))\n",
        "plt.barh(top_10_feature_importance['Feature'], top_10_feature_importance['Mean Absolute SHAP Value'], color='skyblue')\n",
        "plt.xlabel('Mean Absolute SHAP Value')\n",
        "plt.ylabel('Feature')\n",
        "plt.title('Top 10 Feature Importance based on SHAP Values')\n",
        "plt.gca().invert_yaxis()\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8H89Gy10wkLd"
      },
      "source": [
        "**Residual Analysis**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hRIgsr9SwmZQ"
      },
      "outputs": [],
      "source": [
        "# Calculate residuals\n",
        "residuals = y_val - val_predictions.flatten()\n",
        "\n",
        "# Plot residuals\n",
        "plt.figure(figsize=(10, 6))\n",
        "sns.scatterplot(x=val_predictions.flatten(), y=residuals)\n",
        "plt.axhline(y=0, color='r', linestyle='--')\n",
        "plt.title('Residuals vs. Predicted Values')\n",
        "plt.xlabel('Predicted Values')\n",
        "plt.ylabel('Residuals')\n",
        "plt.show()\n",
        "\n",
        "# Plot distribution of residuals\n",
        "plt.figure(figsize=(10, 6))\n",
        "sns.histplot(residuals, bins=20, kde=True)\n",
        "plt.title('Distribution of Residuals')\n",
        "plt.xlabel('Residuals')\n",
        "plt.ylabel('Frequency')\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sDWjqeeZI2Ma"
      },
      "source": [
        "# 5.4 Random Forest Regression"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "kVm6h-8TI64Z"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.model_selection import RandomizedSearchCV\n",
        "from sklearn.ensemble import RandomForestRegressor\n",
        "from sklearn.metrics import mean_squared_error\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "from sklearn.model_selection import cross_val_score\n",
        "from sklearn.metrics import r2_score\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "kBYEsi21JAe-"
      },
      "outputs": [],
      "source": [
        "# Step 1: Initialize the Random Forest Regressor\n",
        "rf_regressor = RandomForestRegressor(random_state=42)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "JBdxB_Z5LK0v"
      },
      "outputs": [],
      "source": [
        "# Step 2: Find the Best Parameters\n",
        "\n",
        "# Define the parameter grid for RandomizedSearchCV\n",
        "param_dist = {\n",
        "    'n_estimators': [50, 100, 150, 200, 250, 300],\n",
        "    'max_depth': [None, 5, 10, 15, 20],\n",
        "    'min_samples_split': [2, 5, 10, 15],\n",
        "    'min_samples_leaf': [1, 2, 4, 6]\n",
        "}\n",
        "\n",
        "# Initialize Random Forest Regressor\n",
        "rf_regressor = RandomForestRegressor(random_state=42)\n",
        "\n",
        "# Initialize RandomizedSearchCV\n",
        "random_search = RandomizedSearchCV(estimator=rf_regressor, param_distributions=param_dist,\n",
        "                                   n_iter=20, cv=5, scoring='neg_mean_squared_error',\n",
        "                                   random_state=42, n_jobs=-1)\n",
        "\n",
        "# Fit RandomizedSearchCV\n",
        "random_search.fit(X_train, y_train)\n",
        "\n",
        "# Get the best parameters\n",
        "best_params = random_search.best_params_\n",
        "print(\"Best Parameters:\", best_params)\n",
        "\n",
        "# Use the best estimator\n",
        "best_rf_regressor = random_search.best_estimator_\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "S8x4ReF8QmvG"
      },
      "source": [
        "  The goal of performing hyperparameter tuning usingRandomizedSearchCV is to find the set of hyperparameters that minimizes the MSE or RMSE on a validation set. The hyperparameters that result in the lowest MSE or RMSE are considered the best hyperparameters for the model.By expanding the range of hyperparameters and increasing n_iter, this allow the search algorithm to explore a wider range of parameter combinations, potentially leading to better model performance."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ArXow85_LMPE"
      },
      "outputs": [],
      "source": [
        "# Step 3: Train the Model with Best Parameters\n",
        "best_rf_regressor.fit(X_train, y_train)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "LV7TkcgQ6aD0"
      },
      "outputs": [],
      "source": [
        "# Step 4: Predict on Validation Set\n",
        "y_val_pred = best_rf_regressor.predict(X_val)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "gldDptz96dIA"
      },
      "outputs": [],
      "source": [
        "# Step 5: Evaluate Model Performance on Validation Set\n",
        "mse_val_rf = mean_squared_error(y_val, y_val_pred)\n",
        "rmse_val_rf = np.sqrt(mse_val_rf)\n",
        "r2_val_rf = best_rf_regressor.score(X_val, y_val)\n",
        "print(\"Mean Squared Error (MSE) on Validation Set:\", mse_val_rf)\n",
        "print(\"Root Mean Squared Error (RMSE) on Validation Set:\", rmse_val_rf)\n",
        "print(\"R-squared (R2) Score on Validation Set:\", r2_val_rf)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "PLu9EONL6f5L"
      },
      "outputs": [],
      "source": [
        "# Step 6: Visualize Results (Actual vs. Predicted Values on Validation Set)\n",
        "plt.figure(figsize=(8, 6))\n",
        "plt.scatter(y_val, y_val_pred, color='blue', alpha=0.5)  # Scatter plot of actual vs. predicted values\n",
        "plt.plot([min(y_val), max(y_val)], [min(y_val), max(y_val)], '--', color='red')  # Diagonal line\n",
        "plt.xlabel('Actual Values')\n",
        "plt.ylabel('Predicted Values')\n",
        "plt.title('Actual vs. Predicted Values (Validation Set)')\n",
        "plt.grid(True)\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "nH7qjtID6kGu"
      },
      "outputs": [],
      "source": [
        "# Step 7: Feature Importance\n",
        "feature_importance = best_rf_regressor.feature_importances_\n",
        "sorted_idx = np.argsort(feature_importance)[::-1]\n",
        "top_features = X.columns[sorted_idx][:10]  # Display top 10 features\n",
        "print(\"Top 10 Important Features:\")\n",
        "for i, feature in enumerate(top_features, 1):\n",
        "    print(f\"{i}. {feature}: {feature_importance[sorted_idx[i-1]]}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qqP44ZU06nmU"
      },
      "outputs": [],
      "source": [
        "# Step 8: Cross-Validation\n",
        "cv_rmse_rf = np.sqrt(-cross_val_score(best_rf_regressor, X_train, y_train, cv=5, scoring=\"neg_mean_squared_error\"))\n",
        "print(\"Cross-Validation RMSE:\", cv_rmse_rf.mean())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9UKyar4s6q5J"
      },
      "outputs": [],
      "source": [
        "# Step 9: Model Evaluation on Test Set\n",
        "y_test_pred = best_rf_regressor.predict(X_test)\n",
        "mse_test_rf = mean_squared_error(y_test, y_test_pred)\n",
        "rmse_test_rf = np.sqrt(mse_test_rf)\n",
        "r2_test_rf = r2_score(y_test, y_test_pred)\n",
        "print(\"\\nModel Evaluation on Test Set:\")\n",
        "print(\"Mean Squared Error (MSE) on Test Set:\", mse_test_rf)\n",
        "print(\"Root Mean Squared Error (RMSE) on Test Set:\", rmse_test_rf)\n",
        "print(\"R-squared (R2) Score on Test Set:\", r2_test_rf)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LFZMpZZfSYrb"
      },
      "source": [
        "The Random Forest Regression model performs well based on various evaluation metrics:\n",
        "\n",
        "The Cross-Validation RMSE suggests the model's ability to generalize to unseen data, with a relatively low value of 0.0979.\n",
        "On the validation set, the model shows good performance with low MSE (0.0086) and RMSE (0.0929) values, indicating small errors in predictions.\n",
        "The R-squared (R2) score on the validation set is 0.6537, suggesting that the model explains about 65.37% of the variance in the target variable.\n",
        "When evaluated on the test set, the model maintains its performance, with MSE (0.0099) and RMSE (0.0995) values similar to those on the validation set. The R-squared (R2) score on the test set is 0.6903, indicating that the model explains about 69.03% of the variance in the test data.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fd0ddG3x6ulJ"
      },
      "outputs": [],
      "source": [
        "# Step 10: Residual Plot\n",
        "residuals = y_val - y_val_pred\n",
        "plt.figure(figsize=(8, 6))\n",
        "plt.scatter(y_val_pred, residuals, color='blue', alpha=0.5)\n",
        "plt.axhline(y=0, color='red', linestyle='--')\n",
        "plt.xlabel('Predicted Values')\n",
        "plt.ylabel('Residuals')\n",
        "plt.title('Residual Plot')\n",
        "plt.grid(True)\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "l3MSOEQ2L_hb"
      },
      "outputs": [],
      "source": [
        "plt.figure(figsize=(10, 6))\n",
        "plt.barh(top_features, feature_importance[sorted_idx][:10], color='skyblue')\n",
        "plt.xlabel('Feature Importance Score')\n",
        "plt.ylabel('Feature')\n",
        "plt.title('Top 10 Important Features')\n",
        "plt.gca().invert_yaxis()\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7mlxM7zKSePk"
      },
      "source": [
        "Overall, these results indicate that the Random Forest Regression model provides accurate predictions, but there is still room for improvement in explaining the variance of the target variable."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TFRghYVjGKCn"
      },
      "source": [
        "# 5.5 Decision Tree Regression"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "k2VQ-yVEV2wO"
      },
      "source": [
        "**Decision Tree Regression**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GuniubacHU6G"
      },
      "source": [
        "**Model Training**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zHVK-Lrkq4cQ"
      },
      "outputs": [],
      "source": [
        "from sklearn.tree import DecisionTreeRegressor\n",
        "\n",
        "# Initialize the Decision Tree Regression model\n",
        "dt_regressor = DecisionTreeRegressor(random_state=42)\n",
        "\n",
        "# Fit the model using the training data\n",
        "dt_regressor.fit(X_train, y_train)\n",
        "\n",
        "# Make predictions using the trained model on the validation set\n",
        "y_pred_val = dt_regressor.predict(X_val)\n",
        "\n",
        "# Make predictions using the trained model on the test set\n",
        "y_pred_test = dt_regressor.predict(X_test)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "M46j27Lzq4XT"
      },
      "outputs": [],
      "source": [
        "#Visualize the prediction\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Visualize predictions on the validation set\n",
        "plt.figure(figsize=(10, 6))\n",
        "plt.scatter(y_val, y_pred_val, color='blue', label='Predicted')\n",
        "plt.plot([min(y_val), max(y_val)], [min(y_val), max(y_val)], linestyle='--', color='red', label='Actual')\n",
        "plt.xlabel('Actual Values')\n",
        "plt.ylabel('Predicted Values')\n",
        "plt.title('Validation Set - Actual vs Predicted')\n",
        "plt.legend()\n",
        "plt.show()\n",
        "\n",
        "# Visualize predictions on the test set\n",
        "plt.figure(figsize=(10, 6))\n",
        "plt.scatter(y_test, y_pred_test, color='green', label='Predicted')\n",
        "plt.plot([min(y_test), max(y_test)], [min(y_test), max(y_test)], linestyle='--', color='orange', label='Actual')\n",
        "plt.xlabel('Actual Values')\n",
        "plt.ylabel('Predicted Values')\n",
        "plt.title('Test Set - Actual vs Predicted')\n",
        "plt.legend()\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aR3rBJP3K6hl"
      },
      "source": [
        "Validation Set - Actual vs Predicted evaluate how well the model performs on the validation data, which was used during the hyperparameter tuning process.\n",
        "\n",
        "Test Set - Actual vs Predicted evaluate the model's performance on the test data, which is unseen during the training and validation phases."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "u78YI-tFHrkD"
      },
      "source": [
        "**Hyperparameter Tuning (Randomized Search)**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Klqo5I8lP4vQ"
      },
      "source": [
        "Pruning: Decision trees are prone to overfitting, where they become too complex and capture noise in the training data. Pruning techniques, such as cost complexity pruning (also known as minimal cost complexity pruning or CCP), can help improve performance by simplifying the tree structure and reducing overfitting."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6CWn_oD5q4Py"
      },
      "outputs": [],
      "source": [
        "from sklearn.model_selection import RandomizedSearchCV\n",
        "\n",
        "# Define the hyperparameter grid\n",
        "param_dist = {\n",
        "    'max_depth': [3, 5, 7, 10, 15, 20, None],\n",
        "    'min_samples_split': [2, 5, 10, 15, 20],\n",
        "    'min_samples_leaf': [1, 2, 4, 6],\n",
        "    'max_features': [1.0, 'sqrt', 'log2', None],\n",
        "    'splitter': ['best', 'random']\n",
        "}"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9lNUyQ_ELoGu"
      },
      "source": [
        "We used randomized search instead of Grid Search is because randomized search explores a random subset of the hyperparameter space, making it more efficient than Grid Search, especially when dealing with a large number of hyperparameters or a wide range of possible values."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "X1LwDrQTyYXI"
      },
      "outputs": [],
      "source": [
        "#Initialize the Decision Tree Regression model\n",
        "\n",
        "from sklearn.tree import DecisionTreeRegressor\n",
        "\n",
        "dt_regressor = DecisionTreeRegressor(random_state=42)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "64pWqQ8Sqtfz"
      },
      "source": [
        "Cross-validation (KFold with 5 splits)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "QvENuQPizm5G"
      },
      "outputs": [],
      "source": [
        "# Import necessary modules\n",
        "from sklearn.model_selection import KFold\n",
        "from sklearn.metrics import mean_squared_error, make_scorer\n",
        "\n",
        "# Define cross-validation strategy\n",
        "cv_strategy = KFold(n_splits=5, shuffle=True, random_state=42)\n",
        "\n",
        "# Perform Randomized Search with cross-validation\n",
        "random_search = RandomizedSearchCV(\n",
        "    estimator=dt_regressor,\n",
        "    param_distributions=param_dist,\n",
        "    n_iter=100,\n",
        "    scoring=make_scorer(mean_squared_error, greater_is_better=False),\n",
        "    cv=cv_strategy,\n",
        "    random_state=42,\n",
        "    n_jobs=-1\n",
        ")\n",
        "\n",
        "# Fit Randomized Search to find the best hyperparameters\n",
        "random_search.fit(X_train, y_train)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LPq1xh_kMOct"
      },
      "source": [
        "K-Fold cross-validation helps reduce bias by using multiple train-test splits, ensuring that the model is trained and tested on different subsets of data. This reduces the risk of overfitting to a particular training set or underestimating the model's performance."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "OEjqpkzvzmuo"
      },
      "outputs": [],
      "source": [
        "#Get the best hyperparameters and initialize the model with best hyperparameters\n",
        "\n",
        "best_params = random_search.best_params_\n",
        "print(\"Best Hyperparameters:\", best_params)\n",
        "\n",
        "best_dt_regressor = DecisionTreeRegressor(random_state=42, **best_params)\n",
        "best_dt_regressor.fit(X_train, y_train)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rrYoImzUM41t"
      },
      "source": [
        "The best hyperparameters found through Randomized Search Cross-Validation for the DecisionTreeRegressor are max_depth=15, max_features=1.0, min_samples_leaf=6, min_samples_split=20, random_state=42, splitter='random'"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "C7KCHYdCyYO_"
      },
      "outputs": [],
      "source": [
        "#Make predictions using the tuned model\n",
        "\n",
        "y_pred_tuned_val = best_dt_regressor.predict(X_val)\n",
        "y_pred_tuned_test = best_dt_regressor.predict(X_test)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "LzFVkLum788v"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Calculate residuals for tuned model on the test set\n",
        "residuals_tuned_test = y_test - y_pred_tuned_test\n",
        "\n",
        "# Create Residual Plot for tuned model on the test set\n",
        "plt.figure(figsize=(10, 6))\n",
        "plt.scatter(y_pred_tuned_test, residuals_tuned_test, color='blue', alpha=0.5)\n",
        "plt.axhline(y=0, color='red', linestyle='--')\n",
        "plt.xlabel('Predicted Values')\n",
        "plt.ylabel('Residuals')\n",
        "plt.title('Residual Plot - Tuned Model (Test Set)')\n",
        "plt.grid(True)\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Jjde9vB_CX1U"
      },
      "source": [
        "From the residual plot, it shows vertical lines or patterns can indicate that our dataset contains discretized features such as 'datetime', 'temperature', 'percipitation', 'wind speed' and 'humidity'. Hence, they can on only a limited set of distinct values and the model predictions are based on these discrete values."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Dv-ViRKpAFPf"
      },
      "outputs": [],
      "source": [
        "# Visualize Actual vs. Predicted on the test set\n",
        "plt.figure(figsize=(10, 6))\n",
        "plt.scatter(y_test, y_pred_tuned_test, color='green', label='Predicted')\n",
        "plt.plot([min(y_test), max(y_test)], [min(y_test), max(y_test)], linestyle='--', color='orange', label='Actual')\n",
        "plt.xlabel('Actual Values')\n",
        "plt.ylabel('Predicted Values')\n",
        "plt.title('Test Set - Actual vs Predicted (Tuned Model)')\n",
        "plt.legend()\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LfVG4F0PISpa"
      },
      "source": [
        "**Model Evaluation**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-plKvglqIVXT"
      },
      "source": [
        "Mean Squared Error (MSE) and Mean Absolute Error (MAE): These metrics measure the average squared or absolute difference between the predicted and actual values. Lower values indicate better performance."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "o0Ca4F5I0IEY"
      },
      "outputs": [],
      "source": [
        "from sklearn.metrics import mean_squared_error, mean_absolute_error\n",
        "\n",
        "# Calculate Mean Squared Error (MSE) and Mean Absolute Error (MAE) for the tuned model\n",
        "mse_tuned_val = mean_squared_error(y_val, y_pred_tuned_val)\n",
        "mae_tuned_val = mean_absolute_error(y_val, y_pred_tuned_val)\n",
        "mse_tuned_test = mean_squared_error(y_test, y_pred_tuned_test)\n",
        "mae_tuned_test = mean_absolute_error(y_test, y_pred_tuned_test)\n",
        "rmse_tuned_val = np.sqrt(mse_tuned_val)\n",
        "rmse_tuned_test = np.sqrt(mse_tuned_test)\n",
        "\n",
        "print(\"Tuned Model - Validation Set Metrics:\")\n",
        "print(f\"Mean Squared Error (MSE): {mse_tuned_val}\")\n",
        "print(f\"Mean Absolute Error (MAE): {mae_tuned_val}\")\n",
        "print(f\"Root Mean Squared Error (RMSE): {rmse_tuned_val}\")\n",
        "\n",
        "print(\"\\nTuned Model - Test Set Metrics:\")\n",
        "print(f\"Mean Squared Error (MSE): {mse_tuned_test}\")\n",
        "print(f\"Mean Absolute Error (MAE): {mae_tuned_test}\")\n",
        "print(f\"Root Mean Squared Error (RMSE): {rmse_tuned_test}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "O_8ye8w8N7VP"
      },
      "source": [
        "The model shows consistent performance metrics (MSE, MAE, RMSE) between the validation and test sets as the values of the performance metrics for both sets are close.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "M_F72maPIa5R"
      },
      "source": [
        "R-squared (R²) Coefficient: This metric provides an indication of how well the model fits the data. It measures the proportion of the variance in the target variable that can be explained by the predictor variables. Higher values (closer to 1) indicate a better fit."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "x179tD7UIcAz"
      },
      "outputs": [],
      "source": [
        "from sklearn.metrics import r2_score\n",
        "\n",
        "# Calculate R-squared (R²) for the tuned model\n",
        "r2_tuned_val = r2_score(y_val, y_pred_tuned_val)\n",
        "r2_tuned_test = r2_score(y_test, y_pred_tuned_test)\n",
        "\n",
        "print(\"Tuned Model - Validation Set Metrics:\")\n",
        "print(f\"R-squared (R²): {r2_tuned_val}\")\n",
        "\n",
        "print(\"\\nTuned Model - Test Set Metrics:\")\n",
        "print(f\"R-squared (R²): {r2_tuned_test}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LoXQqGHrAmmF"
      },
      "source": [
        "The R² values for both sets are decent, with the test set slightly higher, indicating good predictive performance."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Y71MBOorQrkf"
      },
      "source": [
        "Mean Squared Logarithmic Error (MSLE): This metric is commonly used when the target variable is skewed and has a large range. It calculates the average logarithmic difference between the predicted and actual values, penalizing large differences more than small ones."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9z5KCDgPQokb"
      },
      "outputs": [],
      "source": [
        "from sklearn.metrics import mean_squared_log_error\n",
        "\n",
        "# Calculate Mean Squared Logarithmic Error (MSLE) for the tuned model\n",
        "msle_tuned_val = mean_squared_log_error(y_val, y_pred_tuned_val)\n",
        "msle_tuned_test = mean_squared_log_error(y_test, y_pred_tuned_test)\n",
        "\n",
        "print(\"Tuned Model - Validation Set Metrics:\")\n",
        "print(f\"Mean Squared Logarithmic Error (MSLE): {msle_tuned_val}\")\n",
        "\n",
        "print(\"\\nTuned Model - Test Set Metrics:\")\n",
        "print(f\"Mean Squared Logarithmic Error (MSLE): {msle_tuned_test}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UBto4PCsRMZn"
      },
      "source": [
        "The MSLE values for both the validation set (0.005727) and the test set (0.006127) are relatively low, which is a good sign. It indicates that the tuned Decision Tree Regression model is making predictions that are reasonably close to the true values."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VeVe_4d-IstK"
      },
      "source": [
        "Decision Tree Visualization: Decision trees can be visualized to gain insights into their structure and decision-making process. By visualizing the tree, we can understand the splits, feature importance, and how the model partitions the data. This can help identify potential issues like overfitting or imbalanced splits."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-Ty2L5NQ18HZ"
      },
      "outputs": [],
      "source": [
        "from sklearn.tree import plot_tree\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Visualize the decision tree\n",
        "plt.figure(figsize=(70, 8))\n",
        "plot_tree(best_dt_regressor, filled=True, feature_names=X.columns, fontsize=8)\n",
        "plt.title(\"Decision Tree Regression\")\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2_3_hYD7Iv6Y"
      },
      "source": [
        "Feature Importance: Decision trees provide a measure of feature importance based on how much they contribute to the model’s splits. By examining the importance of each feature, we can identify the most influential variables in the model and assess their impact on performance."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "aLDwbZKO18AZ"
      },
      "outputs": [],
      "source": [
        "# Get feature importances\n",
        "feature_importance = best_dt_regressor.feature_importances_\n",
        "\n",
        "# Create a DataFrame to store feature importance\n",
        "feature_importance_df = pd.DataFrame({'Feature': X.columns, 'Importance': feature_importance})\n",
        "\n",
        "# Sort the DataFrame by importance in descending order\n",
        "top_features = feature_importance_df.sort_values(by='Importance', ascending=False).head(10)\n",
        "\n",
        "# Display the top 10 features\n",
        "print(\"Top 10 Features:\")\n",
        "print(top_features)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "i34IXAGN174O"
      },
      "outputs": [],
      "source": [
        "import matplotlib.pyplot as plt\n",
        "from matplotlib.pyplot import figure\n",
        "\n",
        "figure(figsize=(6,6))\n",
        "\n",
        "top_features.sort_values(by='Importance', ascending=True).plot.barh(color='red')\n",
        "plt.title('Visualization of decision tree model deature importance')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fGzjVufILADR"
      },
      "source": [
        "From the graph, we know that temperature gives the more impact for the prediction of change of volume of the lake in 24 hours."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TP-HYjFBfJ-Y"
      },
      "source": [
        "# 5.6 Support Vector Regression (SVR)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xh4_z8XXfOjW"
      },
      "source": [
        "Support Vector Regression (SVR) is a type of Support Vector Machine (SVM) algorithms and is commonly used for regression analysis. It tries to find a function that best predicts the countinous output value of a given input value."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "F1PX8erXy25E"
      },
      "source": [
        "SVR works for both linear and non-linear kernels. A linear kernel is a simple dot product between two input vectors, while a non-linear kernel is a more complex function that can capture more intricate patterns in the data. The choice of kernel mainly depends on the pattern of the dataset."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ElWWqa_ezZgX"
      },
      "source": [
        "There are 5 types of kernel:\n",
        "- linear\n",
        "- rbf\n",
        "- poly\n",
        "- sigmoid\n",
        "- precomputed"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XWWoRS6X0a2O"
      },
      "source": [
        "Sigmoid is better suited for binary classifications purpose and precomputed required dataset with a square matrix.Both of these kernels are not suitable for our datasets. Hence, we will be testing out the performance of the SVR model by applying the remaining types of kernel."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "knqSbSS-2GaU"
      },
      "outputs": [],
      "source": [
        "# Importing required module\n",
        "from sklearn.svm import SVR\n",
        "\n",
        "# Setting up SVR model with different kernel parameter\n",
        "model_lin = SVR(kernel='linear')\n",
        "model_rbf = SVR(kernel='rbf')\n",
        "model_poly = SVR(kernel='poly')\n",
        "\n",
        "# Fit the model with train dataset\n",
        "model_lin.fit(X_train, y_train)\n",
        "model_rbf.fit(X_train, y_train)\n",
        "model_poly.fit(X_train, y_train)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "275LG79IufkC"
      },
      "source": [
        "We now evaluate the performance of the SVR based on their type of kernel used."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2OMV3WeuQdKG"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "from sklearn import metrics\n",
        "# Evaluate performance\n",
        "y_val_pred = model_lin.predict(X_val)\n",
        "r2_score = metrics.r2_score(y_val, y_val_pred)\n",
        "mse = metrics.mean_squared_error(y_val, y_val_pred)\n",
        "rmse = np.sqrt(mse)\n",
        "\n",
        "print(\"Performance for SVR model using kernel = 'linear': \")\n",
        "print(\"Mean Square Error (MSE): \",mse)\n",
        "print(\"Root Mean Square Error (RMSE): \",rmse)\n",
        "print(\"R2-score (R2): \",r2_score)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "nfEEa4BmROOQ"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "from sklearn import metrics\n",
        "# Evaluate performance\n",
        "y_val_pred = model_rbf.predict(X_val)\n",
        "r2_score = metrics.r2_score(y_val, y_val_pred)\n",
        "mse = metrics.mean_squared_error(y_val, y_val_pred)\n",
        "\n",
        "print(\"Performance for SVR model using kernel = 'rbf': \")\n",
        "print(\"Mean Square Error (MSE): \",mse)\n",
        "print(\"Root Mean Square Error (RMSE): \",rmse)\n",
        "print(\"R2-score (R2): \",r2_score)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "uavtIE7cROiN"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "from sklearn import metrics\n",
        "# Evaluate performance\n",
        "y_val_pred = model_poly.predict(X_val)\n",
        "r2_score = metrics.r2_score(y_val, y_val_pred)\n",
        "mse = metrics.mean_squared_error(y_val, y_val_pred)\n",
        "rmse = np.sqrt(mse)\n",
        "\n",
        "print(\"Performance for SVR model using kernel = 'poly': \")\n",
        "print(\"Mean Square Error (MSE): \",mse)\n",
        "print(\"Root Mean Square Error (RMSE): \",rmse)\n",
        "print(\"R2-score (R2): \",r2_score)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nm3nNLOzu1Sx"
      },
      "source": [
        "From the result above, we can see that using 'poly' for the kernel option give us the best performance among the other, with a r2 score of 0.566967, follow by 'rbf' with the r2 score of 0.563317, and 'linear' with the lowest r2 score of 0.462406."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nusd1W-Qvb-1"
      },
      "source": [
        "Since using 'poly' and 'rbf' provide us the similar performance, both of them are selected as the parameter for kernel. Now, we left with two more hyperparameter to tune, which is C and epsilon. We will be using GridSearchCV to test out all the possible combination by providing somes value for each hyperparameter to see which combination give us the best result."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "761gIjs2gTDh"
      },
      "source": [
        "For SVR, there a few tunable hyperparameters which can help to achieve a better fit of the model for the training dataset. The hyperparameters are as following:\n",
        "- C\n",
        "- Epsilon"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4okFs_yA2kKF"
      },
      "source": [
        "Searching for best hyperparameter tunning for kernel = rbf:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "q8cyPr98Ttv_"
      },
      "outputs": [],
      "source": [
        "from sklearn.model_selection import GridSearchCV\n",
        "\n",
        "parameter = {'C': [0.01, 0.05, 0.1, 0.2, 0.5, 1, 2, 5], 'epsilon': [0, 0.1, 0.5, 1, 5, 10, 100]}\n",
        "grid = GridSearchCV(model_rbf, param_grid = parameter, scoring = 'r2', verbose = 1, return_train_score = True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zXNMIrQJaedm"
      },
      "outputs": [],
      "source": [
        "grid.fit(X_train, y_train)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ctWoy-64alU7"
      },
      "outputs": [],
      "source": [
        "print(grid.best_estimator_)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DEug58Qa2vWg"
      },
      "source": [
        "Searching for best hyperparameter tunning for kernel = poly:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "G4NUeG1g0vMl"
      },
      "outputs": [],
      "source": [
        "from sklearn.model_selection import GridSearchCV\n",
        "\n",
        "parameter = {'C': [0.01, 0.05, 0.1, 0.2, 0.5, 1, 2, 5], 'epsilon': [0, 0.1, 0.5, 1, 5, 10, 100]}\n",
        "grid = GridSearchCV(model_poly, param_grid = parameter, scoring = 'r2', verbose = 1, return_train_score = True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dNypbksM0vMu"
      },
      "outputs": [],
      "source": [
        "grid.fit(X_train, y_train)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Pwr_L8o60vMv"
      },
      "outputs": [],
      "source": [
        "print(grid.best_estimator_)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8chZeJ2rw791"
      },
      "source": [
        "Based on the result by GridSearchCV, we test both model with their best hyperparameter tunning and choose the best model.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "YWZ2tyx6hweU"
      },
      "outputs": [],
      "source": [
        "model_poly = SVR(kernel = 'poly', gamma = 'scale', C=0.5, epsilon=0)\n",
        "model_poly.fit(X_train, y_train)\n",
        "\n",
        "import numpy as np\n",
        "from sklearn import metrics\n",
        "# Evaluate performance\n",
        "y_val_pred = model_poly.predict(X_val)\n",
        "r2_score_SVR = metrics.r2_score(y_val, y_val_pred)\n",
        "mse_SVR = metrics.mean_squared_error(y_val, y_val_pred)\n",
        "rmse_SVR = np.sqrt(mse)\n",
        "\n",
        "\n",
        "print(\"Performance for SVR model using kernel = 'poly': \")\n",
        "print(\"Mean Square Error (MSE): \",mse_SVR)\n",
        "print(\"Root Mean Square Error (RMSE): \",rmse_SVR)\n",
        "print(\"R2-score (R2): \",r2_score_SVR)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fIwQQTi-8pg9"
      },
      "outputs": [],
      "source": [
        "model_rbf = SVR(kernel = 'rbf', gamma = 'scale', C=2, epsilon=0)\n",
        "model_rbf.fit(X_train, y_train)\n",
        "\n",
        "import numpy as np\n",
        "from sklearn import metrics\n",
        "# Evaluate performance\n",
        "y_val_pred = model_rbf.predict(X_val)\n",
        "r2_score_SVR = metrics.r2_score(y_val, y_val_pred)\n",
        "mse_SVR = metrics.mean_squared_error(y_val, y_val_pred)\n",
        "rmse_SVR = np.sqrt(mse)\n",
        "\n",
        "\n",
        "print(\"Performance for SVR model using kernel = 'rbf': \")\n",
        "print(\"Mean Square Error (MSE): \",mse_SVR)\n",
        "print(\"Root Mean Square Error (RMSE): \",rmse_SVR)\n",
        "print(\"R2-score (R2): \",r2_score_SVR)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AxbCnsGV3ALR"
      },
      "source": [
        "From the result above, we can see that rbf model have a higher r2-score of 0.595037 compared to poly model with the r2-score of 0.552764\n",
        "\n",
        "Now we use the best model to test the test dataset."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "WgzwD6Si8pg8"
      },
      "outputs": [],
      "source": [
        "model_best = SVR(kernel = 'rbf', gamma = 'scale', C=2, epsilon=0)\n",
        "model_best.fit(X_train, y_train)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Jc0Mh0pY1xRn"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "from sklearn import metrics\n",
        "# Evaluate performance\n",
        "y_test_pred = model_best.predict(X_test)\n",
        "r2_score_test_SVR = metrics.r2_score(y_test, y_test_pred)\n",
        "mse_test_SVR = metrics.mean_squared_error(y_test, y_test_pred)\n",
        "rmse_test_SVR = np.sqrt(mse)\n",
        "\n",
        "\n",
        "print(\"Performance for SVR model using best hyperparameters tuning: \")\n",
        "print(\"Mean Square Error (MSE): \",mse_test_SVR)\n",
        "print(\"Root Mean Square Error (RMSE): \",rmse_test_SVR)\n",
        "print(\"R2-score (R2): \",r2_score_test_SVR)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "D2yAzPDz3YZF"
      },
      "source": [
        "By using Support Vector Regression with the best hyperparameter tunning, we get a performance of 0.012519 for mean square error, 0.111723 for root mean square error and 0.608208 for r2 score. A graph of actual value to the predicted value is plotted as below."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "SvqzGsqIiIc0"
      },
      "outputs": [],
      "source": [
        "plt.figure(figsize=(8, 6))\n",
        "plt.scatter(y_test, y_test_pred, color='blue', alpha=0.5)  # Scatter plot of actual vs. predicted values\n",
        "plt.plot([min(y_test), max(y_test)], [min(y_test), max(y_test)], '--', color='red')  # Diagonal line\n",
        "plt.xlabel('Actual Values')\n",
        "plt.ylabel('Predicted Values')\n",
        "plt.title('Actual vs. Predicted Values')\n",
        "plt.grid(True)\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RZ3t0SNaYtEE"
      },
      "source": [
        "# 5.7 Gaussian Process Regression (GPR)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XsgFc46VXg0h"
      },
      "source": [
        "Gaussian Process Regression (GRP) is a powerful and flexible non-parametric regression technique used in machine learning and statistics. It is useful when dealing with problems involving continuous data, where the relationship between input variables and output is not explicity known or can be complex."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "i4l_aJPlfDlC"
      },
      "source": [
        "Kernel is a very crucial key for Gaussian Process Regression because it helps to determine the shape of prior and posterior of the Gaussian Process Regression.\n",
        "\n",
        "We set up a few kernels for testing."
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "from matplotlib import pyplot as plt\n",
        "from sklearn.gaussian_process import GaussianProcessRegressor\n",
        "from sklearn.gaussian_process.kernels import RBF, ConstantKernel as C, RationalQuadratic as RQ, WhiteKernel, ExpSineSquared as Exp, DotProduct as Lin"
      ],
      "metadata": {
        "id": "2qmdz7Uuj1f0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Gauusian Process Model with no kernel"
      ],
      "metadata": {
        "id": "c2t5uY0d4yd6"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model_0 = GaussianProcessRegressor()\n",
        "model_0.fit(X_train, y_train)\n"
      ],
      "metadata": {
        "id": "PQ4loGeA4js2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "from sklearn import metrics\n",
        "# Evaluate performance\n",
        "y_val_pred = model_0.predict(X_val)\n",
        "r2_score = metrics.r2_score(y_val, y_val_pred)\n",
        "mse = metrics.mean_squared_error(y_val, y_val_pred)\n",
        "rmse = np.sqrt(mse)\n",
        "\n",
        "print(\"Performance for GPR model: \")\n",
        "print(\"Mean Square Error (MSE): \",mse)\n",
        "print(\"Root Mean Square Error (RMSE): \",rmse)\n",
        "print(\"R2-score (R2): \",r2_score)"
      ],
      "metadata": {
        "id": "jcQJvEm14oMW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Gaussian Process Regression without any hyperparameter tunning especially kernel performed poorly with a r2 score of 0.102107. Hence, we prepared some kernel option to test the model out to see which kernel work the best with the Gaussian Process Regression model."
      ],
      "metadata": {
        "id": "CPpiSNGz48wA"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Kernel 1"
      ],
      "metadata": {
        "id": "xiG32wjRiMBM"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "kernel_1 = RBF()\n",
        "model_1 = GaussianProcessRegressor(kernel = kernel_1, n_restarts_optimizer=4)\n",
        "model_1.fit(X_train, y_train)\n"
      ],
      "metadata": {
        "id": "3fkd98jf6Dnz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Kernel 2"
      ],
      "metadata": {
        "id": "aijoGmo6iONa"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "kernel_2 = Lin()\n",
        "model_2 = GaussianProcessRegressor(kernel = kernel_2, n_restarts_optimizer=4)\n",
        "model_2.fit(X_train, y_train)\n"
      ],
      "metadata": {
        "id": "xgECMDgs3nvN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Kernel 3"
      ],
      "metadata": {
        "id": "NLBiHamuiPF_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "kernel_3 = RQ()\n",
        "model_3 = GaussianProcessRegressor(kernel = kernel_3, n_restarts_optimizer=4)\n",
        "model_3.fit(X_train, y_train)\n"
      ],
      "metadata": {
        "id": "XNaY2fs_6EhB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Kernel 4"
      ],
      "metadata": {
        "id": "MdHPAOYRBh1F"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "kernel_4 = C()\n",
        "model_4 = GaussianProcessRegressor(kernel = kernel_4, n_restarts_optimizer=4)\n",
        "model_4.fit(X_train, y_train)\n"
      ],
      "metadata": {
        "id": "OQu969IIBh1F"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Kernel 5"
      ],
      "metadata": {
        "id": "ySDR9iOFBh_F"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "kernel_5 = WhiteKernel()\n",
        "model_5 = GaussianProcessRegressor(kernel = kernel_5, n_restarts_optimizer=4)\n",
        "model_5.fit(X_train, y_train)\n"
      ],
      "metadata": {
        "id": "vEpR5DgZBh_G"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Kernel 6"
      ],
      "metadata": {
        "id": "hC6lh-NiCbG4"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "kernel_6 = Exp()\n",
        "model_6 = GaussianProcessRegressor(kernel = kernel_6, n_restarts_optimizer=4)\n",
        "model_6.fit(X_train, y_train)\n"
      ],
      "metadata": {
        "id": "CqI_PO1eCbG5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "All of the model are fit with different type of kernel. Now, we test the Gaussian Process Regression using the different type of kernels with the validation dataset."
      ],
      "metadata": {
        "id": "L_J0s3F1juiW"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "from sklearn import metrics\n",
        "# Evaluate performance\n",
        "y_val_pred = model_1.predict(X_val)\n",
        "r2_score = metrics.r2_score(y_val, y_val_pred)\n",
        "mse = metrics.mean_squared_error(y_val, y_val_pred)\n",
        "rmse = np.sqrt(mse)\n",
        "\n",
        "print(\"Performance for GRP model using RBF: \")\n",
        "print(\"Mean Square Error (MSE): \",mse)\n",
        "print(\"Root Mean Square Error (RMSE): \",rmse)\n",
        "print(\"R2-score (R2): \",r2_score)"
      ],
      "metadata": {
        "id": "4650A-tTljHt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "from sklearn import metrics\n",
        "# Evaluate performance\n",
        "y_val_pred = model_2.predict(X_val)\n",
        "r2_score = metrics.r2_score(y_val, y_val_pred)\n",
        "mse = metrics.mean_squared_error(y_val, y_val_pred)\n",
        "rmse = np.sqrt(mse)\n",
        "\n",
        "print(\"Performance for GRP model using DotProduct: \")\n",
        "print(\"Mean Square Error (MSE): \",mse)\n",
        "print(\"Root Mean Square Error (RMSE): \",rmse)\n",
        "print(\"R2-score (R2): \",r2_score)"
      ],
      "metadata": {
        "id": "24tktVi0jZjb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "from sklearn import metrics\n",
        "# Evaluate performance\n",
        "y_val_pred = model_3.predict(X_val)\n",
        "r2_score = metrics.r2_score(y_val, y_val_pred)\n",
        "mse = metrics.mean_squared_error(y_val, y_val_pred)\n",
        "rmse = np.sqrt(mse)\n",
        "\n",
        "print(\"Performance for GRP model using RationalQuadratic: \")\n",
        "print(\"Mean Square Error (MSE): \",mse)\n",
        "print(\"Root Mean Square Error (RMSE): \",rmse)\n",
        "print(\"R2-score (R2): \",r2_score)"
      ],
      "metadata": {
        "id": "Ca7dzddlmdFN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "from sklearn import metrics\n",
        "# Evaluate performance\n",
        "y_val_pred = model_4.predict(X_val)\n",
        "r2_score = metrics.r2_score(y_val, y_val_pred)\n",
        "mse = metrics.mean_squared_error(y_val, y_val_pred)\n",
        "rmse = np.sqrt(mse)\n",
        "\n",
        "print(\"Performance for GRP model using ConstantKernel: \")\n",
        "print(\"Mean Square Error (MSE): \",mse)\n",
        "print(\"Root Mean Square Error (RMSE): \",rmse)\n",
        "print(\"R2-score (R2): \",r2_score)"
      ],
      "metadata": {
        "id": "qSJTfJFEBtmm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "from sklearn import metrics\n",
        "# Evaluate performance\n",
        "y_val_pred = model_5.predict(X_val)\n",
        "r2_score = metrics.r2_score(y_val, y_val_pred)\n",
        "mse = metrics.mean_squared_error(y_val, y_val_pred)\n",
        "rmse = np.sqrt(mse)\n",
        "\n",
        "print(\"Performance for GRP model using WhiteKernel: \")\n",
        "print(\"Mean Square Error (MSE): \",mse)\n",
        "print(\"Root Mean Square Error (RMSE): \",rmse)\n",
        "print(\"R2-score (R2): \",r2_score)"
      ],
      "metadata": {
        "id": "_HwYIKIoBt8t"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "from sklearn import metrics\n",
        "# Evaluate performance\n",
        "y_val_pred = model_6.predict(X_val)\n",
        "r2_score = metrics.r2_score(y_val, y_val_pred)\n",
        "mse = metrics.mean_squared_error(y_val, y_val_pred)\n",
        "rmse = np.sqrt(mse)\n",
        "\n",
        "print(\"Performance for GRP model using ExpSineSquared: \")\n",
        "print(\"Mean Square Error (MSE): \",mse)\n",
        "print(\"Root Mean Square Error (RMSE): \",rmse)\n",
        "print(\"R2-score (R2): \",r2_score)"
      ],
      "metadata": {
        "id": "a-CdjW9fCgnP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "From the result above, using Rational Kernel in Gaussian Process Regression performed the best prediction with the r2 score of 0.632909, followed by using Dot Product with the r2 score of 0.479586 and using RBF as the kernel performed the worst among the others with the r2 score of 0.277044.\n",
        "\n",
        "Result using WhiteKernel, ConstantKernel and ExpSineQuared were not included in the comparison as they produced negative r2 score."
      ],
      "metadata": {
        "id": "8IZn04VQAn56"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "We also try out some combination of kernel suggested on the internet to test out the model with our dataset."
      ],
      "metadata": {
        "id": "u_dl_LJuiP7N"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "kernel_C1 = C()*Exp(length_scale = 24, periodicity=1)\n",
        "model_C1 = GaussianProcessRegressor(kernel = kernel_C1, n_restarts_optimizer=4)\n",
        "model_C1.fit(X_train, y_train)\n"
      ],
      "metadata": {
        "id": "AeTneKTp-afS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "kernel_C2 = C()*Exp(length_scale = 24, periodicity=1)*RQ(length_scale = 24, alpha = 0.5, length_scale_bounds = (1e-05,2), alpha_bounds = (1e-05, 100000))\n",
        "model_C2 = GaussianProcessRegressor(kernel = kernel_C2, n_restarts_optimizer=4)\n",
        "model_C2.fit(X_train, y_train)"
      ],
      "metadata": {
        "id": "6UDypL98Dh8u"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "kernel_C3 = C() * RQ(length_scale = 24, alpha = 0.1)\n",
        "model_C3 = GaussianProcessRegressor(kernel = kernel_C3, n_restarts_optimizer=4)\n",
        "model_C3.fit(X_train, y_train)"
      ],
      "metadata": {
        "id": "_1VqlL6BDowb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Let's test out the performance for each kernel."
      ],
      "metadata": {
        "id": "3q_Fxe1mDtMW"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "from sklearn import metrics\n",
        "# Evaluate performance\n",
        "y_val_pred = model_C1.predict(X_val)\n",
        "r2_score = metrics.r2_score(y_val, y_val_pred)\n",
        "mse = metrics.mean_squared_error(y_val, y_val_pred)\n",
        "rmse = np.sqrt(mse)\n",
        "\n",
        "print(\"Performance for GRP model using combination 1: \")\n",
        "print(\"Mean Square Error (MSE): \",mse)\n",
        "print(\"Root Mean Square Error (RMSE): \",rmse)\n",
        "print(\"R2-score (R2): \",r2_score)"
      ],
      "metadata": {
        "id": "8j9cvnqKDtoN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "from sklearn import metrics\n",
        "# Evaluate performance\n",
        "y_val_pred = model_C2.predict(X_val)\n",
        "r2_score = metrics.r2_score(y_val, y_val_pred)\n",
        "mse = metrics.mean_squared_error(y_val, y_val_pred)\n",
        "rmse = np.sqrt(mse)\n",
        "\n",
        "print(\"Performance for GRP model using combination 2: \")\n",
        "print(\"Mean Square Error (MSE): \",mse)\n",
        "print(\"Root Mean Square Error (RMSE): \",rmse)\n",
        "print(\"R2-score (R2): \",r2_score)"
      ],
      "metadata": {
        "id": "UpjN7RYzDuBD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "from sklearn import metrics\n",
        "# Evaluate performance\n",
        "y_val_pred = model_C3.predict(X_val)\n",
        "r2_score = metrics.r2_score(y_val, y_val_pred)\n",
        "mse = metrics.mean_squared_error(y_val, y_val_pred)\n",
        "rmse = np.sqrt(mse)\n",
        "\n",
        "print(\"Performance for GRP model using combination 3: \")\n",
        "print(\"Mean Square Error (MSE): \",mse)\n",
        "print(\"Root Mean Square Error (RMSE): \",rmse)\n",
        "print(\"R2-score (R2): \",r2_score)"
      ],
      "metadata": {
        "id": "omBBB8naDwON"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "From the result above, we see that two of the combination failed to produce prediction with a positive r2 score. Combination 3 has a r2 score of 0.632464 for its performance. However, it is still slightly less than the performance of using just RationalQuadratic kernel only."
      ],
      "metadata": {
        "id": "t0R-trDSH-Qn"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Hence, we will be using RationalQuadratic as th2 kernel for the Gaussian Process Regression to test out the test set."
      ],
      "metadata": {
        "id": "td226bfVIxn5"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "from sklearn import metrics\n",
        "# Evaluate performance\n",
        "y_test_pred = model_3.predict(X_test)\n",
        "r2_score_test_GRP = metrics.r2_score(y_test, y_test_pred)\n",
        "mse_test_GRP = metrics.mean_squared_error(y_test, y_test_pred)\n",
        "rmse_test_GRP = np.sqrt(mse_test_GRP)\n",
        "\n",
        "print(\"Performance for GRP model using RationalQuadratic: \")\n",
        "print(\"Mean Square Error (MSE): \",mse_test_GRP)\n",
        "print(\"Root Mean Square Error (RMSE): \",rmse_test_GRP)\n",
        "print(\"R2-score (R2): \", r2_score_test_GRP)"
      ],
      "metadata": {
        "id": "3DKkezPQImsR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Using Gaussian Process Regression with RationalQuadratic, we obtain a result for mean square error of 0.012112, root mean square error of 0.110054 and a r2 score of 0.620963."
      ],
      "metadata": {
        "id": "7SjUoj75JBUx"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "plt.figure(figsize=(8, 6))\n",
        "plt.scatter(y_test, y_test_pred, color='blue', alpha=0.5)  # Scatter plot of actual vs. predicted values\n",
        "plt.plot([min(y_test), max(y_test)], [min(y_test), max(y_test)], '--', color='red')  # Diagonal line\n",
        "plt.xlabel('Actual Values')\n",
        "plt.ylabel('Predicted Values')\n",
        "plt.title('Actual vs. Predicted Values')\n",
        "plt.grid(True)\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "jj1murxkJl1O"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Sr202-Npd0rI"
      },
      "source": [
        "# 5.8 Auto-sklearn"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1x_0os3Hd4-K"
      },
      "source": [
        "Auto-sklearn is an automated machine toolkit and a drop-in replacement for a scikit-learn estimator. It frees a machine learnig user from algorithm selection and hyperparameter tuning."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zwWPzRIxgi1y"
      },
      "source": [
        "We using auto-sklearn to see how well it's performance is in choosing suitable algorithm and tuning hyperparameter to predict the target."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "04CTdtn1hUoa"
      },
      "source": [
        "First, we need to install auto-sklearn before importing it."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "OUueJZZiua_0"
      },
      "outputs": [],
      "source": [
        "!pip install Cython==0.29.36\n",
        "!pip uninstall scipy -y\n",
        "!pip install scipy==1.9\n",
        "!pip uninstall pyparsing -y\n",
        "!pip install pyparsing==2.4\n",
        "!pip uninstall scikit_learn -y"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Q7UGx_QkvSXh"
      },
      "outputs": [],
      "source": [
        "!pip uninstall imbalanced-learn -y\n",
        "!pip uninstall mlxtend -y\n",
        "!pip uninstall yellowbrick -y"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "QG6X2n0PveKO"
      },
      "outputs": [],
      "source": [
        "!pip install scikit-learn==0.24.2 --no-build-isolation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ceW4d2hQxehT"
      },
      "outputs": [],
      "source": [
        "!pip install auto-sklearn"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pIB_on84iOj9"
      },
      "source": [
        "After successfully install auto-sklearn, we can now import the package and start configuring it."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zbKbxO6llzyz"
      },
      "outputs": [],
      "source": [
        "# Import required package\n",
        "import autosklearn.regression"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "lj4-C9Om1W6h"
      },
      "outputs": [],
      "source": [
        "# Configuring auto-sklearn\n",
        "autosklearn_regressor = autosklearn.regression.AutoSklearnRegressor(\n",
        "    time_left_for_this_task = 240,\n",
        "    per_run_time_limit = 60,\n",
        ")\n",
        "autosklearn_regressor.fit(X_train_ns, y_train_ns)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jvahc47RntE7"
      },
      "source": [
        "We are done configuring the auto-sklearn. Now, let's see what we get from auto-sklearn."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6auvF_sI2Fmc"
      },
      "outputs": [],
      "source": [
        "# Print the info of the model selected and used by the auto-sklearn\n",
        "print(autosklearn_regressor.leaderboard())"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Autosklearn provides us a ensemble models which has contains 68% of gaussian_process and 32% of extra_trees."
      ],
      "metadata": {
        "id": "NarGsABLBtHt"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "autosklearn_regressor.sprint_statistics()"
      ],
      "metadata": {
        "id": "g0EimfLY7Wzv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "autosklearn_regressor.show_models()"
      ],
      "metadata": {
        "id": "oTYBHUHM7Etc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "The above show the model selected and the hyperparameter tunned by autosklearn."
      ],
      "metadata": {
        "id": "JPC_H1KuCFEN"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "HHiDLG0F2cyC"
      },
      "outputs": [],
      "source": [
        "from sklearn.metrics import mean_squared_error, r2_score\n",
        "import numpy as np\n",
        "\n",
        "# Evaluate the model's performance selected by auto-sklearn\n",
        "y_test_pred = autosklearn_regressor.predict(X_test_ns)\n",
        "mse_test_autosklearn = mean_squared_error(y_test_ns, y_test_pred)\n",
        "rmse_test_autosklearn = np.sqrt(mse_test_autosklearn)\n",
        "r2_test_autosklearn = r2_score(y_test_ns, y_test_pred)\n",
        "print(\"\\nModel Evaluation on Test Set:\")\n",
        "print(\"Mean Squared Error (MSE) on Test Set:\", mse_test_autosklearn)\n",
        "print(\"Root Mean Squared Error (RMSE) on Test Set:\", rmse_test_autosklearn)\n",
        "print(\"R-squared (R2) Score on Test Set:\", r2_test_autosklearn)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "The ensemble models produces a pretty good results with a mean squared error of 0.008574, root mean squared error of 0.092598 and a r2 score of 0.731670.\n",
        "\n",
        "We configure another auto sklearn but this time limmiting it to one type of model only."
      ],
      "metadata": {
        "id": "cXQaD3Vf_Vb5"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "f7XZQTRp7-e9"
      },
      "outputs": [],
      "source": [
        "# Configuring auto-sklearn\n",
        "autosklearn_regressor = autosklearn.regression.AutoSklearnRegressor(\n",
        "    time_left_for_this_task = 240,\n",
        "    per_run_time_limit = 60,\n",
        "    ensemble_size = 1,\n",
        "    initial_configurations_via_metalearning = 0,\n",
        ")\n",
        "autosklearn_regressor.fit(X_train_ns, y_train_ns)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "gMUNMil-8Stl"
      },
      "outputs": [],
      "source": [
        "# Print the info of the model selected and used by the auto-sklearn\n",
        "print(autosklearn_regressor.leaderboard())"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Auto sklearn has selected random_forest among the others available models."
      ],
      "metadata": {
        "id": "DNyLlW8kCpM5"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "autosklearn_regressor.sprint_statistics()"
      ],
      "metadata": {
        "id": "eQVANGQm8Stl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "autosklearn_regressor.show_models()"
      ],
      "metadata": {
        "id": "BX0j9Aqn8Stl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "The above show the hyperparameter tunned by the auto sklearn for random forest regression."
      ],
      "metadata": {
        "id": "Zzf1Na2rCyIu"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "f99_93ua8Stl"
      },
      "outputs": [],
      "source": [
        "from sklearn.metrics import mean_squared_error, r2_score\n",
        "import numpy as np\n",
        "\n",
        "# Evaluate the model's performance selected by auto-sklearn\n",
        "y_test_pred = autosklearn_regressor.predict(X_test_ns)\n",
        "mse_test = mean_squared_error(y_test_ns, y_test_pred)\n",
        "rmse_test = np.sqrt(mse_test)\n",
        "r2_test = r2_score(y_test_ns, y_test_pred)\n",
        "print(\"\\nModel Evaluation on Test Set:\")\n",
        "print(\"Mean Squared Error (MSE) on Test Set:\", mse_test)\n",
        "print(\"Root Mean Squared Error (RMSE) on Test Set:\", rmse_test)\n",
        "print(\"R-squared (R2) Score on Test Set:\", r2_test)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Compare to the ensemble models produced by auto sklearn, the model only containing random forest has a r2 score of 0.672243 which is lesser than the ensemble models.\n",
        "\n",
        "This indicate that ensemble models work much better with our datasets."
      ],
      "metadata": {
        "id": "eIyPEUFAC4yv"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "plt.figure(figsize=(8, 6))\n",
        "plt.scatter(y_test_ns, y_test_pred, color='blue', alpha=0.5)  # Scatter plot of actual vs. predicted values\n",
        "plt.plot([min(y_test_ns), max(y_test_ns)], [min(y_test_ns), max(y_test_ns)], '--', color='red')  # Diagonal line\n",
        "plt.xlabel('Actual Values')\n",
        "plt.ylabel('Predicted Values')\n",
        "plt.title('Actual vs. Predicted Values')\n",
        "plt.grid(True)\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "bVGrIdENKAev"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "H9xVDx71wGRQ"
      },
      "source": [
        "# 6.0 Result Summary (Model Evaluation)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "We are using the following performance metrics to evaluate the performance of each of our model:\n",
        "- Mean Squared Error (MSE)\n",
        "- Root Mean Squared Error (RMSE)\n",
        "- R-squared (R2) score"
      ],
      "metadata": {
        "id": "l9-u6996RDPt"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DVAOFVZBDVLm"
      },
      "source": [
        "All of the result of the best performance from each model is summarized in the table below."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "VnZcqoYVzPG4"
      },
      "outputs": [],
      "source": [
        "from IPython.display import HTML, display\n",
        "\n",
        "# Organize all the result into a table\n",
        "result_table = [\n",
        "    {'Types of Model': 'Auto-sklearn', 'Description': 'Model selection by auto sklearn / ensemble_weight:\\ngaussian_process 0.68\\nextra_trees 0.32', 'Mean Squared Error (MSE)': mse_test_autosklearn, 'Root Mean Squared Error (RMSE)': rmse_test_autosklearn, 'R-squared (R2) Score': r2_test_autosklearn},\n",
        "    {'Types of Model': 'Multiple linear Regression', 'Description': 'No hyperparameter tunning', 'Mean Squared Error (MSE)': mse_test_linearM, 'Root Mean Squared Error (RMSE)': rmse_test_linearM, 'R-squared (R2) Score': r2_test_linearM},\n",
        "    {'Types of Model': 'Polynomial Regression', 'Description': 'Polynomial degree : 2\\nRidge Alpha : 10.0', 'Mean Squared Error (MSE)': mse_test_polyM, 'Root Mean Squared Error (RMSE)': rmse_test_polyM, 'R-squared (R2) Score': r2_test_polyM},\n",
        "    {'Types of Model': 'Neural Network Regression', 'Description': 'First dense layer (Optimal no. of unit): 224\\nSecond dense layer (Optimal no. of unit): 288\\nThird dense layer (Optimal no. of unit): 32\\nLearning rate: 0.01', 'Mean Squared Error (MSE)': 0.014184, 'Root Mean Squared Error (RMSE)': 0.119098, 'R-squared (R2) Score': 0.556102},\n",
        "    {'Types of Model': 'Random Forest Regression', 'Description': 'n_estimators: 200\\nmin_samples_split: 5\\nmin_samples_leaf: 1\\nmax_depth: None', 'Mean Squared Error (MSE)': mse_test_rf, 'Root Mean Squared Error (RMSE)': rmse_test_rf, 'R-squared (R2) Score': r2_test_rf},\n",
        "    {'Types of Model': 'Decision Tree Regression', 'Description': 'max_depth: 15\\nmin_samples_leaf: 6\\nmin_samples_split: 20', 'Mean Squared Error (MSE)': mse_tuned_test, 'Root Mean Squared Error (RMSE)': rmse_tuned_test, 'R-squared (R2) Score': r2_tuned_test},\n",
        "    {'Types of Model': 'Support Vector Regression', 'Description': 'kernel: rbf\\ngamma: scale\\nC: 2\\nepsilon: 0', 'Mean Squared Error (MSE)': mse_test_SVR, 'Root Mean Squared Error (RMSE)': rmse_test_SVR, 'R-squared (R2) Score': r2_score_test_SVR},\n",
        "    {'Types of Model': 'Gaussian Process Regression', 'Description': 'kernel: RationalQuadratic\\nn_restarts_optimizer=4', 'Mean Squared Error (MSE)': mse_test_GRP, 'Root Mean Squared Error (RMSE)': rmse_test_GRP, 'R-squared (R2) Score': r2_score_test_GRP}\n",
        "\n",
        "]\n",
        "result_table_df = pd.DataFrame(result_table)\n",
        "display(HTML(result_table_df.to_html().replace('\\\\n', '<br>')))"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "The data is sorted based on their r2 score in descending order where the best model is at the top of the table."
      ],
      "metadata": {
        "id": "zaaV6qmCNwjV"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "937Z0XWhOWpj"
      },
      "outputs": [],
      "source": [
        "# Sorting the table by R2 Score from highest to Lowest\n",
        "display(HTML(result_table_df.sort_values(by = 'R-squared (R2) Score', ascending = False).to_html().replace('\\\\n', '<br>')))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9lok6oTF465f"
      },
      "source": [
        "# 7.0 Conclusion"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "From the result summary above, we can conclude that:\n",
        "- Random Forest Regression has the best performance amongs the other models trained by us.\n",
        "- Random Forest Regression has the lowest mean square error (0.009902) and root mean square error (0.099508) compared to other models.\n",
        "- Random Forest Regression has the highest r2 score of 0.690128 compared to other models.\n",
        "\n",
        "When comparing our best models, which is Random Forest Regression with model produced by auto sklearn, here are our findings:\n",
        "- Auto sklearn produced a ensemble models which perform better than our best models with a r2 score of 0.731670.\n",
        "- When limiting auto sklearn to produce a model instead of an ensemble models, it selected Random Forest Regression as it model and tunned the hyperparameter of the model by itself.\n",
        "- Our Random Forest Regression performs better when comparing with the Random Forest Regression provided by auto sklearn which only has a r2 score of 0.672243.\n",
        "\n",
        "In these days, Machine Learning able to help human in optimizing natural resource management and preventing disaster. Although prediction helps people to make better decision, individual judgements is required since prediction is not always right."
      ],
      "metadata": {
        "id": "9TlfyR0OMtuE"
      }
    }
  ]
}